{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FewShot_maml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Fu2noaDpvCfB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vainaijr/few-shot-maml/blob/master/FewShot_maml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGPnSLTP8F6i",
        "colab_type": "text"
      },
      "source": [
        "# attempt at using TPU in google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXXH4c7Zs8p",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!pip install \\\n",
        "  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch-1.0.0a0+1d94a2b-cp36-cp36m-linux_x86_64.whl  \\\n",
        "  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch_xla-0.1+5622d42-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nfP6bpmZs6D",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import torch_xla\n",
        "import torch_xla\n",
        "import torch_xla_py.utils as xu\n",
        "import torch_xla_py.xla_model as xm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF7kHAIaCyGE",
        "colab_type": "text"
      },
      "source": [
        "# xmode, pdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZjFBTHC0Zi",
        "colab_type": "code",
        "outputId": "63223a70-5c9f-455e-dc9c-cd97faee1a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%xmode Verbose\n",
        "%pdb on"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Verbose\n",
            "Automatic pdb calling has been turned ON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkCr9Nn8Mms",
        "colab_type": "text"
      },
      "source": [
        "# upgrade tb-nightly to use torch.utils.tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPJK6ArUOgUj",
        "colab_type": "code",
        "outputId": "65ad6da0-5b8b-4394-ead3-bee4f9361f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1885
        }
      },
      "source": [
        "%%shell\n",
        "pip install --upgrade tb-nightly\n",
        "pip install torchsummaryX\n",
        "pip install adabound\n",
        "pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
        "pip install tensorwatch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tb-nightly in /usr/local/lib/python3.6/dist-packages (1.14.0a20190611)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.16.4)\n",
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (0.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchsummaryX) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->torchsummaryX) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->torchsummaryX) (1.12.0)\n",
            "Requirement already satisfied: adabound in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from adabound) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (1.16.4)\n",
            "Collecting git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
            "  Cloning https://github.com/Lyken17/pytorch-OpCounter.git to /tmp/pip-req-build-oknzv7sj\n",
            "  Running command git clone -q https://github.com/Lyken17/pytorch-OpCounter.git /tmp/pip-req-build-oknzv7sj\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from thop==0.0.22) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->thop==0.0.22) (1.16.4)\n",
            "Building wheels for collected packages: thop\n",
            "  Building wheel for thop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zikckk_y/wheels/79/0e/29/2d013ff0d3e36ae48894c11a6a9eecad6bc4789849f5ed802a\n",
            "Successfully built thop\n",
            "Installing collected packages: thop\n",
            "  Found existing installation: thop 0.0.22\n",
            "    Uninstalling thop-0.0.22:\n",
            "      Successfully uninstalled thop-0.0.22\n",
            "Successfully installed thop-0.0.22\n",
            "Collecting tensorwatch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/17/7115c666b03775ca687c5d81e38269286f7029c4658980d879073364a8c3/tensorwatch-0.8.5.tar.gz (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (1.16.4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (17.0.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (3.6.1)\n",
            "Collecting torchstat (from tensorwatch)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/fe/f483b907ca80c90f189cd892bb2ce7b2c256010b30314bbec4fc17d1b5f1/torchstat-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (7.4.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (4.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from tensorwatch) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorwatch) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorwatch) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorwatch) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorwatch) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly->tensorwatch) (2.21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly->tensorwatch) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly->tensorwatch) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly->tensorwatch) (4.4.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->tensorwatch) (1.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torchstat->tensorwatch) (0.24.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchstat->tensorwatch) (1.1.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->tensorwatch) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->tensorwatch) (4.3.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->tensorwatch) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->tensorwatch) (3.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->tensorwatch) (0.21.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->tensorwatch) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->tensorwatch) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->tensorwatch) (0.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorwatch) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorwatch) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorwatch) (2.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorwatch) (1.0.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorwatch) (4.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->tensorwatch) (41.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->tensorwatch) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->tensorwatch) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->tensorwatch) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->tensorwatch) (1.24.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->tensorwatch) (5.2.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->tensorwatch) (4.5.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (1.0.16)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (2.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (4.7.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (5.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->tensorwatch) (0.13.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->tensorwatch) (0.46)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->tensorwatch) (0.6.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (5.5.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (2.10.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets->tensorwatch) (0.5.1)\n",
            "Building wheels for collected packages: tensorwatch\n",
            "  Building wheel for tensorwatch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/d7/11/b0d26a125f5d7b2034051bfc8ed4fd5c5d7cbe73c23baedde6\n",
            "Successfully built tensorwatch\n",
            "Installing collected packages: torchstat, tensorwatch\n",
            "Successfully installed tensorwatch-0.8.5 torchstat-0.0.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDbtVmXz8Wq-",
        "colab_type": "text"
      },
      "source": [
        "# mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6yKpP_IS0F",
        "colab_type": "code",
        "outputId": "87880e7d-a911-47c5-ea54-9fc328f1e2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiUxhtyJ8aw2",
        "colab_type": "text"
      },
      "source": [
        "# setup dynamic visualization in tensorboard (using ngrok)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0404q9CR-uc",
        "colab_type": "code",
        "outputId": "87694b67-2b45-468a-bdd4-01ba9d19bb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-11 16:58:06--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.72.245.79, 34.206.36.121, 52.22.145.207, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.72.245.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.88M  38.9MB/s    in 0.4s    \n",
            "\n",
            "2019-06-11 16:58:07 (38.9 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4dbpe-wR-tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = '/gdrive/My\\ Drive/runs/mouimoto'\n",
        "get_ipython().system_raw(\n",
        "    \"tensorboard --logdir {} --host 0.0.0.0 --port 6006 &\".format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFl1jdrR-sh",
        "colab_type": "code",
        "outputId": "fb909e4a-ca05-4687-9939-94296cac56fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://658efb3e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuhrtRtn8htJ",
        "colab_type": "text"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbi7rvJISrRd",
        "colab_type": "code",
        "outputId": "18930c6b-dc3f-4df9-b949-a59543cc64a8",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch import cat, topk, bmm, stack, norm, zeros, ones, sum, transpose, save, load, manual_seed, cuda\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Module\n",
        "from torch.nn import init\n",
        "from torch.nn import Embedding\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import Upsample\n",
        "from torch.nn import ReflectionPad2d, ZeroPad2d\n",
        "from torch.nn import Conv2d, ConvTranspose2d, Linear\n",
        "from torch.nn import BatchNorm1d, BatchNorm2d, InstanceNorm2d\n",
        "from torch.nn import PixelShuffle\n",
        "from torch.nn import Dropout, Dropout2d\n",
        "from torch.nn import LeakyReLU, ReLU, PReLU, Softmax, Tanh, Sigmoid\n",
        "from torch.nn import AdaptiveAvgPool2d, AdaptiveMaxPool2d, MaxPool2d, AvgPool2d\n",
        "from torch.nn import RNN, LSTM\n",
        "from torch.nn import MSELoss, L1Loss, BCELoss, NLLLoss, BCEWithLogitsLoss, CrossEntropyLoss\n",
        "\n",
        "from torch.nn.functional import relu6, avg_pool2d, softmax, interpolate, linear, conv2d, batch_norm\n",
        "from torch.nn.functional import relu, sigmoid\n",
        "\n",
        "from torch.autograd import grad, Variable as V\n",
        "from torch.nn.utils import weight_norm \n",
        "from torch.optim import Adam, SGD, LBFGS\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
        "from torch.utils.data import DataLoader, Dataset, sampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.checkpoint import checkpoint as cp\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomResizedCrop, ToTensor, Normalize\n",
        "from torchvision.transforms import CenterCrop, Resize, ColorJitter, ToPILImage, RandomCrop, RandomSizedCrop\n",
        "from torchvision.models import ResNet, vgg19, vgg19_bn, densenet201, resnet101, resnet34, resnext101_32x8d\n",
        "from torchvision.models import resnet152, resnet18, vgg16 \n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "from torchsummaryX import summary\n",
        "import tensorwatch as tw\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.weight_norm import WeightNorm\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from abc import abstractmethod\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torch.optim\n",
        "import json\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import adabound\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import h5py\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from thop import profile\n",
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "identity = lambda x:x\n",
        "step_ = 0\n",
        "step__ = 0\n",
        "stepp = 0\n",
        "writer = SummaryWriter(log_dir='/gdrive/My Drive/runs/mouimoto')\n",
        "unloader = ToPILImage()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z07HQ-kL8mBb",
        "colab_type": "text"
      },
      "source": [
        "# setup save directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCkOujho8lXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "save_dir = '/gdrive/My Drive/few_shot/save_dir_mouimoto'\n",
        "data_dir = {}\n",
        "data_dir['CUB'] = '/gdrive/My Drive/CUB/'\n",
        "data_dir['mouimoto'] = '/gdrive/My Drive/mouimoto/'\n",
        "# data_dir['miniImagenet']    = './filelists/miniImagenet/' \n",
        "# data_dir['omniglot']        = './filelists/omniglot/' \n",
        "# data_dir['emnist']          = './filelists/emnist/' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSjsUzgH8sMz",
        "colab_type": "text"
      },
      "source": [
        "# models -> ConvNet, ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8JEnfF-pPAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is modified from https://github.com/facebookresearch/low-shot-shrink-hallucinate\n",
        "\n",
        "# Basic ResNet model\n",
        "\n",
        "def init_layer(L):\n",
        "    # print(\"init_layer\")\n",
        "    classname = L.__class__.__name__\n",
        "    # Initialization using fan-in\n",
        "    if isinstance(L, nn.Conv2d):\n",
        "        n = L.kernel_size[0]*L.kernel_size[1]*L.out_channels\n",
        "        L.weight.data.normal_(0, math.sqrt(2.0/float(n)))\n",
        "    elif isinstance(L, nn.BatchNorm2d):\n",
        "        L.weight.data.fill_(1)\n",
        "        L.bias.data.fill_(0)\n",
        "    elif classname.find(\"Linear\") != -1:\n",
        "        init.normal_(L.weight.data, 0.0, 0.02)\n",
        "\n",
        "class distLinear(nn.Module):\n",
        "    def __init__(self, indim, outdim):\n",
        "        super(distLinear, self).__init__()\n",
        "        self.L = nn.Linear( indim, outdim, bias = False)\n",
        "        self.class_wise_learnable_norm = True  #See the issue#4&8 in the github \n",
        "        if self.class_wise_learnable_norm:      \n",
        "            WeightNorm.apply(self.L, 'weight', dim=0) #split the weight update component to direction and norm      \n",
        "\n",
        "        if outdim <=200:\n",
        "            self.scale_factor = 2; #a fixed scale factor to scale the output of cos value into a reasonably large input for softmax\n",
        "        else:\n",
        "            self.scale_factor = 10; #in omniglot, a larger scale factor is required to handle >1000 output classes.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = torch.norm(x, p=2, dim =1).unsqueeze(1).expand_as(x)\n",
        "        x_normalized = x.div(x_norm+ 0.00001)\n",
        "        if not self.class_wise_learnable_norm:\n",
        "            L_norm = torch.norm(self.L.weight.data, p=2, dim =1).unsqueeze(1).expand_as(self.L.weight.data)\n",
        "            self.L.weight.data = self.L.weight.data.div(L_norm + 0.00001)\n",
        "        cos_dist = self.L(x_normalized) #matrix product by forward function, but when using WeightNorm, this also multiply the cosine distance by a class-wise learnable norm, see the issue#4&8 in the github\n",
        "        scores = self.scale_factor* (cos_dist) \n",
        "\n",
        "        return scores\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "\n",
        "class Linear_fw(nn.Linear): #used in MAML to forward input with fast weight \n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear_fw, self).__init__(in_features, out_features)\n",
        "        self.weight.fast = None #Lazy hack to add fast weight link\n",
        "        self.bias.fast = None\n",
        "#         print(\"__init__Linear_fw\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.weight.fast is not None and self.bias.fast is not None:\n",
        "            out = F.linear(x, self.weight.fast, self.bias.fast) #weight.fast (fast weight) is the temporaily adapted weight\n",
        "#             print(\"forward_Linear_fw_fast\")\n",
        "        else:\n",
        "#             print(\"forward_Linear_fw_1\")\n",
        "#             grid_ = make_grid(x)\n",
        "            # print(\"x.size() {}\".format(x.size()))\n",
        "            # writer.add_image('out_Linear_fw', x)\n",
        "            out = super(Linear_fw, self).forward(x)\n",
        "            # print(\"out.size() {}\".format(out.size()))\n",
        "            # print(\"out.shape {}\".format(out.shape))\n",
        "#             print(\"forward_Linear_fw_2\")\n",
        "            \n",
        "            \n",
        "        return out\n",
        "\n",
        "class Conv2d_fw(nn.Conv2d): #used in MAML to forward input with fast weight \n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,padding=0, bias = True):\n",
        "        super(Conv2d_fw, self).__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "        self.weight.fast = None\n",
        "        if not self.bias is None:\n",
        "            self.bias.fast = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"Conv2d_fw_x.size() {}\".format(x.size()))\n",
        "#         print(\"self.bias {}\".format(self.bias))\n",
        "#         print(\"self.weight.fast {}\".format(self.weight.fast))\n",
        "#         print(\"self.bias.fast {}\".format(self.bias.fast))\n",
        "        if self.bias is None:\n",
        "            if self.weight.fast is not None:\n",
        "                out = F.conv2d(x, self.weight.fast, None, stride= self.stride, padding=self.padding)\n",
        "            else:\n",
        "                out = super(Conv2d_fw, self).forward(x)\n",
        "        else:\n",
        "            if self.weight.fast is not None and self.bias.fast is not None:\n",
        "                out = F.conv2d(x, self.weight.fast, self.bias.fast, stride= self.stride, padding=self.padding)\n",
        "            else:\n",
        "                out = super(Conv2d_fw, self).forward(x)\n",
        "        \n",
        "#         T = out\n",
        "#         ER = T\n",
        "#         print(\"T.unsqueeze {}\".format(ER.unsqueeze(2).size()))\n",
        "#         grid___ = make_grid(T.view(out.size(0) * out.size(1), 1, out.size(2), out.size(3)), nrow=8)\n",
        "#         # make_grid()\n",
        "#         print(\"out size {}\".format(out.size()))\n",
        "#         print(\"grid size {}\".format(grid___.size()))\n",
        "        \n",
        "#         writer.add_image(\"Conv2d_fw_1\", grid___, 0, dataformats='CHW')\n",
        "        \n",
        "        \n",
        "        # print(\"Conv2d_fw_out.shape {}\".format(out.shape))\n",
        "        return out\n",
        "            \n",
        "class BatchNorm2d_fw(nn.BatchNorm2d): #used in MAML to forward input with fast weight \n",
        "    def __init__(self, num_features):\n",
        "        super(BatchNorm2d_fw, self).__init__(num_features)\n",
        "        self.weight.fast = None\n",
        "        self.bias.fast = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"BatchNorm2d_fw_x.size() {}\".format(x.size()))\n",
        "        running_mean = torch.zeros(x.data.size()[1]).cuda()\n",
        "        running_var = torch.ones(x.data.size()[1]).cuda()\n",
        "        if self.weight.fast is not None and self.bias.fast is not None:\n",
        "            out = F.batch_norm(x, running_mean, running_var, self.weight.fast, self.bias.fast, training = True, momentum = 1)\n",
        "            #batch_norm momentum hack: follow hack of Kate Rakelly in pytorch-maml/src/layers.py\n",
        "        else:\n",
        "            out = F.batch_norm(x, running_mean, running_var, self.weight, self.bias, training = True, momentum = 1)\n",
        "        # print(\"BatchNorm2d_fw_out.size() {}\".format(out.size()))\n",
        "        # print(\"BatchNorm2d_fw_out.shape {}\".format(out.shape))\n",
        "        return out\n",
        "\n",
        "# Simple Conv Block\n",
        "class ConvBlock(nn.Module):\n",
        "    maml = False #Default\n",
        "    def __init__(self, indim, outdim, pool = True, padding = 1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.indim  = indim\n",
        "        self.outdim = outdim\n",
        "        if self.maml:\n",
        "            self.C      = Conv2d_fw(indim, outdim, 3, padding = padding)\n",
        "            self.BN     = BatchNorm2d_fw(outdim)\n",
        "        else:\n",
        "            self.C      = nn.Conv2d(indim, outdim, 3, padding= padding)\n",
        "            self.BN     = nn.BatchNorm2d(outdim)\n",
        "        self.relu   = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.parametrized_layers = [self.C, self.BN, self.relu]\n",
        "        if pool:\n",
        "            self.pool   = nn.MaxPool2d(2)\n",
        "            self.parametrized_layers.append(self.pool)\n",
        "\n",
        "        for layer in self.parametrized_layers:\n",
        "            init_layer(layer)\n",
        "\n",
        "        self.trunk = nn.Sequential(*self.parametrized_layers)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # print(\"ConvBlock_x.size() {}\".format(x.size()))\n",
        "        out = self.trunk(x)\n",
        "#         grid = make_grid(out)\n",
        "#         writer.add_image('ConvBlock', grid)\n",
        "        # print(\"ConvBlock_out.size() {}\".format(out.size()))\n",
        "        # print(\"ConvBlock_out.shape {}\".format(out.shape))\n",
        "        return out\n",
        "\n",
        "# # Simple ResNet Block\n",
        "class SimpleBlock(nn.Module):\n",
        "    maml = False #Default\n",
        "    def __init__(self, indim, outdim, half_res):\n",
        "        super(SimpleBlock, self).__init__()\n",
        "        self.indim = indim\n",
        "        self.outdim = outdim\n",
        "        if self.maml:\n",
        "            self.C1 = Conv2d_fw(indim, outdim, kernel_size=3, stride=2 if half_res else 1, padding=1, bias=False)\n",
        "            self.BN1 = BatchNorm2d_fw(outdim)\n",
        "            self.C2 = Conv2d_fw(outdim, outdim,kernel_size=3, padding=1,bias=False)\n",
        "            self.BN2 = BatchNorm2d_fw(outdim)\n",
        "        else:\n",
        "            self.C1 = nn.Conv2d(indim, outdim, kernel_size=3, stride=2 if half_res else 1, padding=1, bias=False)\n",
        "            self.BN1 = nn.BatchNorm2d(outdim)\n",
        "            self.C2 = nn.Conv2d(outdim, outdim,kernel_size=3, padding=1,bias=False)\n",
        "            self.BN2 = nn.BatchNorm2d(outdim)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.parametrized_layers = [self.C1, self.C2, self.BN1, self.BN2]\n",
        "\n",
        "        self.half_res = half_res\n",
        "\n",
        "        # if the input number of channels is not equal to the output, then need a 1x1 convolution\n",
        "        if indim!=outdim:\n",
        "            if self.maml:\n",
        "                self.shortcut = Conv2d_fw(indim, outdim, 1, 2 if half_res else 1, bias=False)\n",
        "                self.BNshortcut = BatchNorm2d_fw(outdim)\n",
        "            else:\n",
        "                self.shortcut = nn.Conv2d(indim, outdim, 1, 2 if half_res else 1, bias=False)\n",
        "                self.BNshortcut = nn.BatchNorm2d(outdim)\n",
        "\n",
        "            self.parametrized_layers.append(self.shortcut)\n",
        "            self.parametrized_layers.append(self.BNshortcut)\n",
        "            self.shortcut_type = '1x1'\n",
        "        else:\n",
        "            self.shortcut_type = 'identity'\n",
        "\n",
        "        for layer in self.parametrized_layers:\n",
        "            init_layer(layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.C1(x)\n",
        "        out = self.BN1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.C2(out)\n",
        "        out = self.BN2(out)\n",
        "        short_out = x if self.shortcut_type == 'identity' else self.BNshortcut(self.shortcut(x))\n",
        "        out = out + short_out\n",
        "        out = self.relu2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# Bottleneck block\n",
        "class BottleneckBlock(nn.Module):\n",
        "    maml = False #Default\n",
        "    def __init__(self, indim, outdim, half_res):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        bottleneckdim = int(outdim/4)\n",
        "        self.indim = indim\n",
        "        self.outdim = outdim\n",
        "        if self.maml:\n",
        "            self.C1 = Conv2d_fw(indim, bottleneckdim, kernel_size=1,  bias=False)\n",
        "            self.BN1 = BatchNorm2d_fw(bottleneckdim)\n",
        "            self.C2 = Conv2d_fw(bottleneckdim, bottleneckdim, kernel_size=3, stride=2 if half_res else 1,padding=1)\n",
        "            self.BN2 = BatchNorm2d_fw(bottleneckdim)\n",
        "            self.C3 = Conv2d_fw(bottleneckdim, outdim, kernel_size=1, bias=False)\n",
        "            self.BN3 = BatchNorm2d_fw(outdim)\n",
        "        else:\n",
        "            self.C1 = nn.Conv2d(indim, bottleneckdim, kernel_size=1,  bias=False)\n",
        "            self.BN1 = nn.BatchNorm2d(bottleneckdim)\n",
        "            self.C2 = nn.Conv2d(bottleneckdim, bottleneckdim, kernel_size=3, stride=2 if half_res else 1,padding=1)\n",
        "            self.BN2 = nn.BatchNorm2d(bottleneckdim)\n",
        "            self.C3 = nn.Conv2d(bottleneckdim, outdim, kernel_size=1, bias=False)\n",
        "            self.BN3 = nn.BatchNorm2d(outdim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.parametrized_layers = [self.C1, self.BN1, self.C2, self.BN2, self.C3, self.BN3]\n",
        "        self.half_res = half_res\n",
        "\n",
        "\n",
        "        # if the input number of channels is not equal to the output, then need a 1x1 convolution\n",
        "        if indim!=outdim:\n",
        "            if self.maml:\n",
        "                self.shortcut = Conv2d_fw(indim, outdim, 1, stride=2 if half_res else 1, bias=False)\n",
        "            else:\n",
        "                self.shortcut = nn.Conv2d(indim, outdim, 1, stride=2 if half_res else 1, bias=False)\n",
        "\n",
        "            self.parametrized_layers.append(self.shortcut)\n",
        "            self.shortcut_type = '1x1'\n",
        "        else:\n",
        "            self.shortcut_type = 'identity'\n",
        "\n",
        "        for layer in self.parametrized_layers:\n",
        "            init_layer(layer)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        short_out = x if self.shortcut_type == 'identity' else self.shortcut(x)\n",
        "        out = self.C1(x)\n",
        "        out = self.BN1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.C2(out)\n",
        "        out = self.BN2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.C3(out)\n",
        "        out = self.BN3(out)\n",
        "        out = out + short_out\n",
        "\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, depth, flatten = True):\n",
        "        super(ConvNet,self).__init__()\n",
        "        trunk = []\n",
        "        for i in range(depth):\n",
        "            indim = 3 if i == 0 else 64\n",
        "            outdim = 64\n",
        "            B = ConvBlock(indim, outdim, pool = ( i <4 ) ) #only pooling for fist 4 layers\n",
        "            trunk.append(B)\n",
        "\n",
        "        if flatten:\n",
        "            trunk.append(Flatten())\n",
        "        # print(\"ConvNet_init\")\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "        self.final_feat_dim = 1600\n",
        "      \n",
        "    def forward(self,x):\n",
        "#         print(\"ConvNet_forward\")\n",
        "        # print('ConvNet_x size {}'.format(x.size()))\n",
        "        # print('ConvNet_x shape {}'.format(x.shape))\n",
        "        \n",
        "        \n",
        "        # grid = make_grid(x)\n",
        "        # writer.add_image('x_', grid)\n",
        "        out = self.trunk(x)\n",
        "        # print('ConvNet_out size {}'.format(out.size()))\n",
        "        \n",
        "        \n",
        "#         plt.figure(figsize=(8,8))\n",
        "#         plt.axis(\"off\")\n",
        "#         plt.imshow(out.data.cpu().numpy())\n",
        "#         plt.show()\n",
        "\n",
        "#         grid = make_grid(out)\n",
        "#         writer.add_image('ConvNet', grid)\n",
        "        return out\n",
        "\n",
        "class ConvNetNopool(nn.Module): #Relation net use a 4 layer conv with pooling in only first two layers, else no pooling\n",
        "    def __init__(self, depth):\n",
        "        super(ConvNetNopool,self).__init__()\n",
        "        trunk = []\n",
        "        for i in range(depth):\n",
        "            indim = 3 if i == 0 else 64\n",
        "            outdim = 64\n",
        "            B = ConvBlock(indim, outdim, pool = ( i in [0,1] ), padding = 0 if i in[0,1] else 1  ) #only first two layer has pooling and no padding\n",
        "            trunk.append(B)\n",
        "\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "        self.final_feat_dim = [64,19,19]\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.trunk(x)\n",
        "        return out\n",
        "\n",
        "class ConvNetS(nn.Module): #For omniglot, only 1 input channel, output dim is 64\n",
        "    def __init__(self, depth, flatten = True):\n",
        "        super(ConvNetS,self).__init__()\n",
        "        trunk = []\n",
        "        for i in range(depth):\n",
        "            indim = 1 if i == 0 else 64\n",
        "            outdim = 64\n",
        "            B = ConvBlock(indim, outdim, pool = ( i <4 ) ) #only pooling for fist 4 layers\n",
        "            trunk.append(B)\n",
        "\n",
        "        if flatten:\n",
        "            trunk.append(Flatten())\n",
        "\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "        self.final_feat_dim = 64\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = x[:,0:1,:,:] #only use the first dimension\n",
        "        out = self.trunk(out)\n",
        "        return out\n",
        "\n",
        "class ConvNetSNopool(nn.Module): #Relation net use a 4 layer conv with pooling in only first two layers, else no pooling. For omniglot, only 1 input channel, output dim is [64,5,5]\n",
        "    def __init__(self, depth):\n",
        "        super(ConvNetSNopool,self).__init__()\n",
        "        trunk = []\n",
        "        for i in range(depth):\n",
        "            indim = 1 if i == 0 else 64\n",
        "            outdim = 64\n",
        "            B = ConvBlock(indim, outdim, pool = ( i in [0,1] ), padding = 0 if i in[0,1] else 1  ) #only first two layer has pooling and no padding\n",
        "            trunk.append(B)\n",
        "\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "        self.final_feat_dim = [64,5,5]\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = x[:,0:1,:,:] #only use the first dimension\n",
        "        out = self.trunk(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    maml = False #Default\n",
        "    def __init__(self,block,list_of_num_layers, list_of_out_dims, flatten = True):\n",
        "        # list_of_num_layers specifies number of layers in each stage\n",
        "        # list_of_out_dims specifies number of output channel for each stage\n",
        "        super(ResNet,self).__init__()\n",
        "        assert len(list_of_num_layers)==4, 'Can have only four stages'\n",
        "        if self.maml:\n",
        "            conv1 = Conv2d_fw(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                                               bias=False)\n",
        "            bn1 = BatchNorm2d_fw(64)\n",
        "        else:\n",
        "            conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                                               bias=False)\n",
        "            bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        relu = nn.ReLU()\n",
        "        pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        init_layer(conv1)\n",
        "        init_layer(bn1)\n",
        "\n",
        "\n",
        "        trunk = [conv1, bn1, relu, pool1]\n",
        "\n",
        "        indim = 64\n",
        "        for i in range(4):\n",
        "\n",
        "            for j in range(list_of_num_layers[i]):\n",
        "                half_res = (i>=1) and (j==0)\n",
        "                B = block(indim, list_of_out_dims[i], half_res)\n",
        "                trunk.append(B)\n",
        "                indim = list_of_out_dims[i]\n",
        "\n",
        "        if flatten:\n",
        "            avgpool = nn.AvgPool2d(7)\n",
        "            trunk.append(avgpool)\n",
        "            trunk.append(Flatten())\n",
        "            self.final_feat_dim = indim\n",
        "        else:\n",
        "            self.final_feat_dim = [ indim, 7, 7]\n",
        "\n",
        "        self.trunk = nn.Sequential(*trunk)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.trunk(x)\n",
        "        return out\n",
        "\n",
        "def Conv4():\n",
        "    print(\"ConvNet(4)\")\n",
        "    return ConvNet(4)\n",
        "\n",
        "def Conv6():\n",
        "    print(\"ConvNet(6)\")\n",
        "    return ConvNet(6)\n",
        "\n",
        "def Conv4NP():\n",
        "    return ConvNetNopool(4)\n",
        "\n",
        "def Conv6NP():\n",
        "    return ConvNetNopool(6)\n",
        "\n",
        "  \n",
        "def Conv4S():\n",
        "    return ConvNetS(4)\n",
        "\n",
        "def Conv4SNP():\n",
        "    return ConvNetSNopool(4)\n",
        "\n",
        "def ResNet10( flatten = True):\n",
        "    return ResNet(SimpleBlock, [1,1,1,1],[64,128,256,512], flatten)\n",
        "\n",
        "def ResNet18( flatten = True):\n",
        "    return ResNet(SimpleBlock, [2,2,2,2],[64,128,256,512], flatten)\n",
        "\n",
        "def ResNet34( flatten = True):\n",
        "    return ResNet(SimpleBlock, [3,4,6,3],[64,128,256,512], flatten)\n",
        "\n",
        "def ResNet50( flatten = True):\n",
        "    return ResNet(BottleneckBlock, [3,4,6,3], [256,512,1024,2048], flatten)\n",
        "\n",
        "def ResNet101( flatten = True):\n",
        "    return ResNet(BottleneckBlock, [3,4,23,3],[256,512,1024,2048], flatten)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOjERIoH84Ep",
        "colab_type": "text"
      },
      "source": [
        "# meta template for different meta learning techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0m0sAgI29Tz",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class MetaTemplate(nn.Module):\n",
        "    def __init__(self, model_func, n_way, n_support, change_way = True):\n",
        "        super().__init__()\n",
        "        # print(\"__init__\")\n",
        "        self.n_way      = n_way\n",
        "        self.n_support  = n_support\n",
        "        self.n_query    = -1 #(change depends on input) \n",
        "        self.feature    = model_func()\n",
        "        self.feat_dim   = self.feature.final_feat_dim\n",
        "        self.change_way = change_way  #some methods allow different_way classification during training and test\n",
        "        \n",
        "\n",
        "    @abstractmethod\n",
        "    def set_forward(self,x,is_feature):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_forward_loss(self, x):\n",
        "        pass\n",
        "\n",
        "    def forward(self,x):\n",
        "        # print(\"forward\")\n",
        "        out  = self.feature.forward(x)\n",
        "        return out\n",
        "\n",
        "    def parse_feature(self,x,is_feature):\n",
        "        x    = V(x.cuda())\n",
        "        \n",
        "#         print(\"parse_feature_x.size() {}\".format(x.size()))\n",
        "        \n",
        "        if is_feature:\n",
        "            z_all = x\n",
        "        else:\n",
        "            x           = x.contiguous().view( self.n_way * (self.n_support + self.n_query), *x.size()[2:]) \n",
        "            z_all       = self.feature.forward(x)\n",
        "            z_all       = z_all.view( self.n_way, self.n_support + self.n_query, -1)\n",
        "        z_support   = z_all[:, :self.n_support]\n",
        "        z_query     = z_all[:, self.n_support:]\n",
        "        \n",
        "#         global step__\n",
        "#         step__ += 1\n",
        "#         x_ = make_grid(z_support)\n",
        "#         writer.add_image('support_data', x_, step__)\n",
        "        \n",
        "#         y_ = make_grid(z_query)\n",
        "#         writer.add_image('query_data', y_, step__) \n",
        "\n",
        "        return z_support, z_query\n",
        "\n",
        "    def correct(self, x):       \n",
        "        scores = self.set_forward(x)\n",
        "        y_query = np.repeat(range( self.n_way ), self.n_query )\n",
        "#         print(\"correct\")\n",
        "        topk_scores, topk_labels = scores.data.topk(1, 1, True, True)\n",
        "        topk_ind = topk_labels.cpu().numpy()\n",
        "        top1_correct = np.sum(topk_ind[:,0] == y_query)\n",
        "        return float(top1_correct), len(y_query)\n",
        "\n",
        "    def train_loop(self, epoch, train_loader, optimizer ):\n",
        "        print_freq = 10\n",
        "        global stepp\n",
        "        avg_loss=0\n",
        "#         print(\"train_loop\")\n",
        "        for i, (x,_ ) in enumerate(train_loader):\n",
        "            self.n_query = x.size(1) - self.n_support           \n",
        "            if self.change_way:\n",
        "                self.n_way  = x.size(0)\n",
        "            optimizer.zero_grad()\n",
        "            loss = self.set_forward_loss( x )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            avg_loss = avg_loss+loss.item()\n",
        "\n",
        "            if i % print_freq==0:\n",
        "                #print(optimizer.state_dict()['param_groups'][0]['lr'])\n",
        "                print('Epoch {:d} | Batch {:d}/{:d} | Loss {:f}'.format(epoch, i, len(train_loader), \n",
        "                                                                        avg_loss/float(i+1)))\n",
        "                stepp += 1\n",
        "                writer.add_scalar('loss_epoch', avg_loss/float(i+1), stepp)\n",
        "                \n",
        "\n",
        "    def test_loop(self, test_loader, record = None):\n",
        "        correct =0\n",
        "        count = 0\n",
        "        acc_all = []\n",
        "#         print(\"test_loop\")\n",
        "        iter_num = len(test_loader) \n",
        "        for i, (x,_) in enumerate(test_loader):\n",
        "            self.n_query = x.size(1) - self.n_support\n",
        "            if self.change_way:\n",
        "                self.n_way  = x.size(0)\n",
        "            correct_this, count_this = self.correct(x)\n",
        "            acc_all.append(correct_this/ count_this*100  )\n",
        "\n",
        "        acc_all  = np.asarray(acc_all)\n",
        "        acc_mean = np.mean(acc_all)\n",
        "        acc_std  = np.std(acc_all)\n",
        "        \n",
        "        print('%d Test Acc = %4.2f%% +- %4.2f%%' %(iter_num,  acc_mean, 1.96* acc_std/np.sqrt(iter_num)))\n",
        "\n",
        "        return acc_mean\n",
        "\n",
        "    def set_forward_adaptation(self, x, is_feature = True): #further adaptation, default is fixing feature and train a new softmax clasifier\n",
        "        assert is_feature == True, 'Feature is fixed in further adaptation'\n",
        "        print(\"set_forward_adaptation\")\n",
        "        z_support, z_query  = self.parse_feature(x,is_feature)\n",
        "\n",
        "        z_support   = z_support.contiguous().view(self.n_way* self.n_support, -1 )\n",
        "        z_query     = z_query.contiguous().view(self.n_way* self.n_query, -1 )\n",
        "\n",
        "        y_support = torch.from_numpy(np.repeat(range( self.n_way ), self.n_support ))\n",
        "        y_support = V(y_support.cuda())\n",
        "\n",
        "        linear_clf = Linear(self.feat_dim, self.n_way)\n",
        "        linear_clf = linear_clf.cuda()\n",
        "\n",
        "        set_optimizer = SGD(linear_clf.parameters(), lr = 0.01, momentum=0.9, dampening=0.9, weight_decay=0.001)\n",
        "\n",
        "        loss_function = CrossEntropyLoss()\n",
        "        loss_function = loss_function.cuda()\n",
        "        \n",
        "        batch_size = 4\n",
        "        support_size = self.n_way* self.n_support\n",
        "        for epoch in range(100):\n",
        "            rand_id = np.random.permutation(support_size)\n",
        "            for i in range(0, support_size , batch_size):\n",
        "                set_optimizer.zero_grad()\n",
        "                selected_id = torch.from_numpy( rand_id[i: min(i+batch_size, support_size) ]).cuda()\n",
        "                z_batch = z_support[selected_id]\n",
        "                y_batch = y_support[selected_id] \n",
        "                scores = linear_clf(z_batch)\n",
        "                loss = loss_function(scores,y_batch)\n",
        "                loss.backward()\n",
        "\n",
        "        scores = linear_clf(z_query)\n",
        "        return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WxA9wNH8-9j",
        "colab_type": "text"
      },
      "source": [
        "# loading dataset, applying transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT8g9tWYTC4e",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "# Copyright 2017-present, Facebook, Inc.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "\n",
        "transformtypedict=dict(Brightness=ImageEnhance.Brightness, Contrast=ImageEnhance.Contrast, Sharpness=ImageEnhance.Sharpness, Color=ImageEnhance.Color)\n",
        "\n",
        "\n",
        "\n",
        "class ImageJitter(object):\n",
        "    def __init__(self, transformdict):\n",
        "        self.transforms = [(transformtypedict[k], transformdict[k]) for k in transformdict]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        out = img\n",
        "        randtensor = torch.rand(len(self.transforms))\n",
        "\n",
        "        for i, (transformer, alpha) in enumerate(self.transforms):\n",
        "            r = alpha*(randtensor[i]*2.0 -1.0) + 1\n",
        "            out = transformer(out).enhance(r).convert('RGB')\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3mLJehkTUw7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# This code is modified from https://github.com/facebookresearch/low-shot-shrink-hallucinate\n",
        "\n",
        "class TransformLoader:\n",
        "    def __init__(self, image_size, \n",
        "                 normalize_param    = dict(mean= [0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]),\n",
        "                 jitter_param       = dict(Brightness=0.4, Contrast=0.4, Color=0.4)):\n",
        "        self.image_size = image_size\n",
        "        self.normalize_param = normalize_param\n",
        "        self.jitter_param = jitter_param\n",
        "    \n",
        "    def parse_transform(self, transform_type):\n",
        "        if transform_type=='ImageJitter':\n",
        "            method = add_transforms.ImageJitter( self.jitter_param )\n",
        "            return method\n",
        "        method = getattr(transforms, transform_type)\n",
        "        if transform_type=='RandomSizedCrop':\n",
        "            return method(self.image_size) \n",
        "        elif transform_type=='CenterCrop':\n",
        "            return method(self.image_size) \n",
        "        elif transform_type=='Resize':\n",
        "            return method([int(self.image_size*1.15), int(self.image_size*1.15)])\n",
        "        elif transform_type=='Normalize':\n",
        "            return method(**self.normalize_param )\n",
        "        else:\n",
        "            return method()\n",
        "\n",
        "    def get_composed_transform(self, aug = False):\n",
        "        if aug:\n",
        "            transform_list = ['RandomSizedCrop', 'ImageJitter', 'RandomHorizontalFlip', 'ToTensor', 'Normalize']\n",
        "        else:\n",
        "            transform_list = ['Resize','CenterCrop', 'ToTensor', 'Normalize']\n",
        "\n",
        "        transform_funcs = [ self.parse_transform(x) for x in transform_list]\n",
        "        transform = transforms.Compose(transform_funcs)\n",
        "        return transform\n",
        "\n",
        "class DataManager:\n",
        "    @abstractmethod\n",
        "    def get_data_loader(self, data_file, aug):\n",
        "        pass \n",
        "\n",
        "\n",
        "class SimpleDataManager(DataManager):\n",
        "    def __init__(self, image_size, batch_size):        \n",
        "        super(SimpleDataManager, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.trans_loader = TransformLoader(image_size)\n",
        "\n",
        "    def get_data_loader(self, data_file, aug): #parameters that would change on train/val set\n",
        "        transform = self.trans_loader.get_composed_transform(aug)\n",
        "        dataset = SimpleDataset(data_file, transform)\n",
        "        data_loader_params = dict(batch_size = self.batch_size, shuffle = True, num_workers = 12, pin_memory = True)       \n",
        "        data_loader = torch.utils.data.DataLoader(dataset, **data_loader_params)\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "class SetDataManager(DataManager):\n",
        "    def __init__(self, image_size, n_way, n_support, n_query, n_eposide =100):        \n",
        "        super(SetDataManager, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.n_way = n_way\n",
        "        self.batch_size = n_support + n_query\n",
        "        self.n_eposide = n_eposide\n",
        "\n",
        "        self.trans_loader = TransformLoader(image_size)\n",
        "\n",
        "    def get_data_loader(self, data_file, aug): #parameters that would change on train/val set\n",
        "        transform = self.trans_loader.get_composed_transform(aug)\n",
        "        dataset = SetDataset( data_file , self.batch_size, transform )\n",
        "        sampler = EpisodicBatchSampler(len(dataset), self.n_way, self.n_eposide )  \n",
        "        data_loader_params = dict(batch_sampler = sampler,  num_workers = 12, pin_memory = True)       \n",
        "        data_loader = torch.utils.data.DataLoader(dataset, **data_loader_params)\n",
        "        return data_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN7UUtrzTZD0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class SimpleDataset:\n",
        "    def __init__(self, data_file, transform, target_transform=identity):\n",
        "        with open(data_file, 'r') as f:\n",
        "            self.meta = json.load(f)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        image_path = os.path.join(self.meta['image_names'][i])\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        target = self.target_transform(self.meta['image_labels'][i])\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta['image_names'])\n",
        "\n",
        "\n",
        "class SetDataset:\n",
        "    def __init__(self, data_file, batch_size, transform):\n",
        "        with open(data_file, 'r') as f:\n",
        "            self.meta = json.load(f)\n",
        " \n",
        "        self.cl_list = np.unique(self.meta['image_labels']).tolist()\n",
        "\n",
        "        self.sub_meta = {}\n",
        "        for cl in self.cl_list:\n",
        "            self.sub_meta[cl] = []\n",
        "\n",
        "        for x,y in zip(self.meta['image_names'],self.meta['image_labels']):\n",
        "            self.sub_meta[y].append(x)\n",
        "\n",
        "        self.sub_dataloader = [] \n",
        "        sub_data_loader_params = dict(batch_size = batch_size,\n",
        "                                  shuffle = True,\n",
        "                                  num_workers = 0, #use main thread only or may receive multiple batches\n",
        "                                  pin_memory = False)        \n",
        "        for cl in self.cl_list:\n",
        "            sub_dataset = SubDataset(self.sub_meta[cl], cl, transform = transform )\n",
        "            self.sub_dataloader.append( torch.utils.data.DataLoader(sub_dataset, **sub_data_loader_params) )\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        return next(iter(self.sub_dataloader[i]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cl_list)\n",
        "\n",
        "class SubDataset:\n",
        "    def __init__(self, sub_meta, cl, transform=transforms.ToTensor(), target_transform=identity):\n",
        "        self.sub_meta = sub_meta\n",
        "        self.cl = cl \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        #print( '%d -%d' %(self.cl,i))\n",
        "        image_path = os.path.join( self.sub_meta[i])\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        target = self.target_transform(self.cl)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sub_meta)\n",
        "\n",
        "class EpisodicBatchSampler(object):\n",
        "    def __init__(self, n_classes, n_way, n_episodes):\n",
        "        self.n_classes = n_classes\n",
        "        self.n_way = n_way\n",
        "        self.n_episodes = n_episodes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_episodes\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(self.n_episodes):\n",
        "            yield torch.randperm(self.n_classes)[:self.n_way]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU6xx8qYTc9g",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class SimpleHDF5Dataset:\n",
        "    def __init__(self, file_handle = None):\n",
        "        if file_handle == None:\n",
        "            self.f = ''\n",
        "            self.all_feats_dset = []\n",
        "            self.all_labels = []\n",
        "            self.total = 0 \n",
        "        else:\n",
        "            self.f = file_handle\n",
        "            self.all_feats_dset = self.f['all_feats'][...]\n",
        "            self.all_labels = self.f['all_labels'][...]\n",
        "            self.total = self.f['count'][0]\n",
        "           # print('here')\n",
        "    def __getitem__(self, i):\n",
        "        return torch.Tensor(self.all_feats_dset[i,:]), int(self.all_labels[i])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total\n",
        "\n",
        "def init_loader(filename):\n",
        "    with h5py.File(filename, 'r') as f:\n",
        "        fileset = SimpleHDF5Dataset(f)\n",
        "\n",
        "    #labels = [ l for l  in fileset.all_labels if l != 0]\n",
        "    feats = fileset.all_feats_dset\n",
        "    labels = fileset.all_labels\n",
        "    while np.sum(feats[-1]) == 0:\n",
        "        feats  = np.delete(feats,-1,axis = 0)\n",
        "        labels = np.delete(labels,-1,axis = 0)\n",
        "        \n",
        "    class_list = np.unique(np.array(labels)).tolist() \n",
        "    inds = range(len(labels))\n",
        "\n",
        "    cl_data_file = {}\n",
        "    for cl in class_list:\n",
        "        cl_data_file[cl] = []\n",
        "    for ind in inds:\n",
        "        cl_data_file[labels[ind]].append( feats[ind])\n",
        "\n",
        "    return cl_data_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn1P4fnr9KU2",
        "colab_type": "text"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmWQpOueT5Vu",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "def one_hot(y, num_class):         \n",
        "    return torch.zeros((len(y), num_class)).scatter_(1, y.unsqueeze(1), 1)\n",
        "\n",
        "def DBindex(cl_data_file):\n",
        "    class_list = cl_data_file.keys()\n",
        "    cl_num= len(class_list)\n",
        "    cl_means = []\n",
        "    stds = []\n",
        "    DBs = []\n",
        "    for cl in class_list:\n",
        "        cl_means.append( np.mean(cl_data_file[cl], axis = 0) )\n",
        "        stds.append( np.sqrt(np.mean( np.sum(np.square( cl_data_file[cl] - cl_means[-1]), axis = 1))))\n",
        "\n",
        "    mu_i = np.tile( np.expand_dims( np.array(cl_means), axis = 0), (len(class_list),1,1) )\n",
        "    mu_j = np.transpose(mu_i,(1,0,2))\n",
        "    mdists = np.sqrt(np.sum(np.square(mu_i - mu_j), axis = 2))\n",
        "    \n",
        "    for i in range(cl_num):\n",
        "        DBs.append( np.max([ (stds[i]+ stds[j])/mdists[i,j]  for j in range(cl_num) if j != i ]) )\n",
        "    return np.mean(DBs)\n",
        "\n",
        "def sparsity(cl_data_file):\n",
        "    class_list = cl_data_file.keys()\n",
        "    cl_sparsity = []\n",
        "    for cl in class_list:\n",
        "        cl_sparsity.append(np.mean([np.sum(x!=0) for x in cl_data_file[cl] ])  ) \n",
        "\n",
        "    return np.mean(cl_sparsity) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "6y9d2OlkHycK",
        "colab": {}
      },
      "source": [
        "\n",
        "model_dict = dict(\n",
        "    Conv4 = Conv4,\n",
        "            Conv4S = Conv4S,\n",
        "            Conv6 = Conv6,\n",
        "            ResNet10 = ResNet10,\n",
        "            ResNet18 = ResNet18,\n",
        "            ResNet34 = ResNet34,\n",
        "            ResNet50 = ResNet50,\n",
        "             ResNet101 = ResNet101\n",
        "    )\n",
        "\n",
        "def get_assigned_file(checkpoint_dir,num):\n",
        "    assign_file = os.path.join(checkpoint_dir, '{:d}.tar'.format(num))\n",
        "    return assign_file\n",
        "\n",
        "def get_resume_file(checkpoint_dir):\n",
        "    filelist = glob.glob(os.path.join(checkpoint_dir, '*.tar'))\n",
        "    if len(filelist) == 0:\n",
        "        return None\n",
        "\n",
        "    filelist =  [ x  for x in filelist if os.path.basename(x) != 'best_model.tar' ]\n",
        "    epochs = np.array([int(os.path.splitext(os.path.basename(x))[0]) for x in filelist])\n",
        "    max_epoch = np.max(epochs)\n",
        "    resume_file = os.path.join(checkpoint_dir, '{:d}.tar'.format(max_epoch))\n",
        "    return resume_file\n",
        "\n",
        "def get_best_file(checkpoint_dir):    \n",
        "    best_file = os.path.join(checkpoint_dir, 'best_model.tar')\n",
        "    if os.path.isfile(best_file):\n",
        "        return best_file\n",
        "    else:\n",
        "        return get_resume_file(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu2noaDpvCfB",
        "colab_type": "text"
      },
      "source": [
        "# CyclicCosineAnnealingLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83xZierSvFgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from bisect import bisect_right,bisect_left\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "class CyclicCosAnnealingLR(_LRScheduler):\n",
        "    r\"\"\"\n",
        "    \n",
        "    Implements reset on milestones inspired from CosineAnnealingLR pytorch\n",
        "    \n",
        "    Set the learning rate of each parameter group using a cosine annealing\n",
        "    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n",
        "    :math:`T_{cur}` is the number of epochs since the last restart in SGDR:\n",
        "    .. math::\n",
        "        \\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\n",
        "        \\cos(\\frac{T_{cur}}{T_{max}}\\pi))\n",
        "    When last_epoch > last set milestone, lr is automatically set to \\eta_{min}\n",
        "    It has been proposed in\n",
        "    `SGDR: Stochastic Gradient Descent with Warm Restarts`_. Note that this only\n",
        "    implements the cosine annealing part of SGDR, and not the restarts.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        milestones (list of ints): List of epoch indices. Must be increasing.\n",
        "        decay_milestones(list of ints):List of increasing epoch indices. Ideally,decay values should overlap with milestone points\n",
        "        gamma (float): factor by which to decay the max learning rate at each decay milestone\n",
        "        eta_min (float): Minimum learning rate. Default: 1e-6\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "        \n",
        "        \n",
        "    .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n",
        "        https://arxiv.org/abs/1608.03983\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer,milestones,decay_milestones=None, gamma=0.5,eta_min=1e-6, last_epoch=-1):\n",
        "        if not list(milestones) == sorted(milestones):\n",
        "            raise ValueError('Milestones should be a list of'\n",
        "                             ' increasing integers. Got {}', milestones)\n",
        "        self.eta_min = eta_min\n",
        "        self.milestones=milestones\n",
        "        self.milestones2=decay_milestones\n",
        "        \n",
        "        self.gamma = gamma\n",
        "        super(CyclicCosAnnealingLR, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        \n",
        "        if self.last_epoch >= self.milestones[-1]:\n",
        "            return [self.eta_min for base_lr in self.base_lrs]\n",
        "\n",
        "        idx = bisect_right(self.milestones,self.last_epoch)\n",
        "        \n",
        "        \n",
        "        \n",
        "        left_barrier = 0 if idx==0 else self.milestones[idx-1]\n",
        "        right_barrier = self.milestones[idx]\n",
        "\n",
        "\n",
        "        width = right_barrier - left_barrier\n",
        "        curr_pos = self.last_epoch- left_barrier \n",
        "        \n",
        "        \n",
        "        if self.milestones2:\n",
        "            return [self.eta_min + ( base_lr* self.gamma ** bisect_right(self.milestones2,self.last_epoch)- self.eta_min) *\n",
        "                   (1 + math.cos(math.pi * curr_pos/ width)) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [self.eta_min + (base_lr - self.eta_min) *\n",
        "               (1 + math.cos(math.pi * curr_pos/ width)) / 2\n",
        "                for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class CyclicLinearLR(_LRScheduler):\n",
        "    r\"\"\"\n",
        "    Implements reset on milestones inspired from Linear learning rate decay\n",
        "    \n",
        "    Set the learning rate of each parameter group using a linear decay\n",
        "    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n",
        "    :math:`T_{cur}` is the number of epochs since the last restart:\n",
        "    .. math::\n",
        "        \\eta_t = \\eta_{min} + (\\eta_{max} - \\eta_{min})(1 -\\frac{T_{cur}}{T_{max}})\n",
        "    When last_epoch > last set milestone, lr is automatically set to \\eta_{min}\n",
        "  \n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        milestones (list of ints): List of epoch indices. Must be increasing.\n",
        "        decay_milestones(list of ints):List of increasing epoch indices. Ideally,decay values should overlap with milestone points\n",
        "        gamma (float): factor by which to decay the max learning rate at each decay milestone\n",
        "        eta_min (float): Minimum learning rate. Default: 1e-6\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "    .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n",
        "        https://arxiv.org/abs/1608.03983\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer,milestones, decay_milestones=None,gamma=0.5, eta_min=1e-6, last_epoch=-1):\n",
        "        if not list(milestones) == sorted(milestones):\n",
        "            raise ValueError('Milestones should be a list of'\n",
        "                             ' increasing integers. Got {}', milestones)\n",
        "        self.eta_min = eta_min\n",
        "        \n",
        "        self.gamma = gamma\n",
        "        self.milestones=milestones\n",
        "        self.milestones2=decay_milestones\n",
        "        super(CyclicLinearLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \n",
        "        if self.last_epoch >= self.milestones[-1]:\n",
        "            return [self.eta_min for base_lr in self.base_lrs]\n",
        "\n",
        "        idx = bisect_right(self.milestones,self.last_epoch)\n",
        "        \n",
        "        left_barrier = 0 if idx==0 else self.milestones[idx-1]\n",
        "        right_barrier = self.milestones[idx]\n",
        "\n",
        "        width = right_barrier - left_barrier\n",
        "        curr_pos = self.last_epoch- left_barrier \n",
        "        \n",
        "        if self.milestones2:\n",
        "            return [self.eta_min + (base_lr* self.gamma ** bisect_right(self.milestones2,self.last_epoch) - self.eta_min) *\n",
        "               (1. - 1.0*curr_pos/ width)\n",
        "                for base_lr in self.base_lrs]\n",
        "        \n",
        "        else:\n",
        "            return [self.eta_min + (base_lr - self.eta_min) *\n",
        "               (1. - 1.0*curr_pos/ width)\n",
        "                for base_lr in self.base_lrs]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VReyf5dZcKPq",
        "colab_type": "text"
      },
      "source": [
        "# yellowfinOptimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdi5WpUecMgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "import logging\n",
        "import os\n",
        "import pickle as cp\n",
        "\n",
        "# eps for numerical stability\n",
        "eps = 1e-6\n",
        "\n",
        "class YFOptimizer(object):\n",
        "  def __init__(self, var_list, lr=0.0001, mu=0.0, clip_thresh=None, weight_decay=0.0,\n",
        "    beta=0.999, curv_win_width=20, zero_debias=True, sparsity_debias=False, delta_mu=0.0, \n",
        "    auto_clip_fac=None, force_non_inc_step=False, h_max_log_smooth=True, h_min_log_smooth=True, \n",
        "    checkpoint_interval=1000, verbose=False, adapt_clip=True, stat_protect_fac=100.0, catastrophic_move_thresh=100.0,\n",
        "    use_disk_checkpoint=False, checkpoint_dir='./YF_workspace'):\n",
        "    '''\n",
        "    clip thresh is the threshold value on ||lr * gradient||\n",
        "    delta_mu can be place holder/variable/python scalar. They are used for additional\n",
        "    momentum in situations such as asynchronous-parallel training. The default is 0.0\n",
        "    for basic usage of the optimizer.\n",
        "    Args:\n",
        "      lr: python scalar. The initial value of learning rate, we use 1.0 in our paper.\n",
        "      mu: python scalar. The initial value of momentum, we use 0.0 in our paper.\n",
        "      clip_thresh: python scalar. The manaully-set clipping threshold for tf.clip_by_global_norm.\n",
        "        if None, the automatic clipping can be carried out. The automatic clipping \n",
        "        feature is parameterized by argument auto_clip_fac. The auto clip feature\n",
        "        can be switched off with auto_clip_fac = None\n",
        "      beta: python scalar. The smoothing parameter for estimations.\n",
        "      sparsity_debias: gradient norm and curvature are biased to larger values when \n",
        "      calculated with sparse gradient. This is useful when the model is very sparse,\n",
        "      e.g. LSTM with word embedding. For non-sparse CNN, turning it off could slightly\n",
        "      accelerate the speed.\n",
        "      delta_mu: for extensions. Not necessary in the basic use. \n",
        "      force_non_inc_step: in some very rare cases, it is necessary to force ||lr * gradient||\n",
        "      to be not increasing dramatically for stableness after some iterations. \n",
        "      In practice, if turned on, we enforce lr * sqrt(smoothed ||grad||^2) \n",
        "      to be less than 2x of the minimal value of historical value on smoothed || lr * grad ||. \n",
        "      This feature is turned off by default.\n",
        "      checkpoint_interval: interval to do checkpointing. For potential recovery from crashing.\n",
        "      stat_protect_fac: a loose hard adaptive threshold over ||grad||^2. It is to protect stat\n",
        "      from being destropied by exploding gradient.\n",
        "    Other features:\n",
        "      If you want to manually control the learning rates, self.lr_factor is\n",
        "      an interface to the outside, it is an multiplier for the internal learning rate\n",
        "      in YellowFin. It is helpful when you want to do additional hand tuning\n",
        "      or some decaying scheme to the tuned learning rate in YellowFin. \n",
        "      Example on using lr_factor can be found here:\n",
        "      https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/pytorch-cifar/main.py#L109\n",
        "    '''\n",
        "    self._lr = lr\n",
        "    self._mu = mu\n",
        "    self._lr_t = lr\n",
        "    self._mu_t = mu\n",
        "    # we convert var_list from generator to list so that\n",
        "    # it can be used for multiple times\n",
        "    self._var_list = list(var_list)\n",
        "    self._clip_thresh = clip_thresh\n",
        "    self._auto_clip_fac = auto_clip_fac\n",
        "    self._beta = beta\n",
        "    self._curv_win_width = curv_win_width\n",
        "    self._zero_debias = zero_debias\n",
        "    self._sparsity_debias = sparsity_debias\n",
        "    self._force_non_inc_step = force_non_inc_step\n",
        "    self._optimizer = torch.optim.SGD(self._var_list, lr=self._lr, \n",
        "      momentum=self._mu, weight_decay=weight_decay)\n",
        "    self._iter = 0\n",
        "    # global states are the statistics\n",
        "    self._global_state = {}\n",
        "\n",
        "    # for decaying learning rate and etc.\n",
        "    self._lr_factor = 1.0\n",
        "\n",
        "    # smoothing options\n",
        "    self._h_max_log_smooth = h_max_log_smooth\n",
        "    self._h_min_log_smooth = h_min_log_smooth\n",
        "\n",
        "    # checkpoint interval\n",
        "    self._checkpoint_interval = checkpoint_interval\n",
        "\n",
        "    self._verbose = verbose\n",
        "    if self._verbose:\n",
        "      logging.debug('Verbose mode with debugging info logged.')\n",
        "\n",
        "    # clip exploding gradient\n",
        "    self._adapt_clip = adapt_clip\n",
        "    self._exploding_grad_clip_thresh=1e3\n",
        "    self._exploding_grad_clip_target_value = 1e3\n",
        "    self._stat_protect_fac = stat_protect_fac\n",
        "    self._catastrophic_move_thresh = catastrophic_move_thresh\n",
        "    self._exploding_grad_detected = False\n",
        "\n",
        "    # workspace creation\n",
        "    self._use_disk_checkpoint = use_disk_checkpoint\n",
        "    self._checkpoint_dir = checkpoint_dir\n",
        "    if use_disk_checkpoint:\n",
        "      if not os.path.exists(self._checkpoint_dir):\n",
        "        os.makedirs(self._checkpoint_dir)\n",
        "      self._checkpoint_file = \"checkpoint_pid_\" + str(os.getpid())\n",
        "\n",
        "\n",
        "  def state_dict(self):\n",
        "    # for checkpoint saving\n",
        "    sgd_state_dict = self._optimizer.state_dict()\n",
        "    # for recover model internally in case of numerical issue\n",
        "    model_state_list = [p.data \\\n",
        "      for group in self._optimizer.param_groups for p in group['params'] ]\n",
        "    global_state = self._global_state\n",
        "    lr_factor = self._lr_factor\n",
        "    iter = self._iter\n",
        "    lr = self._lr\n",
        "    mu = self._mu\n",
        "    clip_thresh = self._clip_thresh\n",
        "    beta = self._beta\n",
        "    curv_win_width = self._curv_win_width\n",
        "    zero_debias = self._zero_debias\n",
        "    h_min = self._h_min\n",
        "    h_max = self._h_max\n",
        "\n",
        "    return {\n",
        "      \"sgd_state_dict\": sgd_state_dict,\n",
        "      \"model_state_list\": model_state_list,\n",
        "      \"global_state\": global_state,\n",
        "      \"lr_factor\": lr_factor,\n",
        "      \"iter\": iter,\n",
        "      \"lr\": lr,\n",
        "      \"mu\": mu,\n",
        "      \"clip_thresh\": clip_thresh,\n",
        "      \"beta\": beta,\n",
        "      \"curv_win_width\": curv_win_width,\n",
        "      \"zero_debias\": zero_debias,\n",
        "      \"h_min\": h_min,\n",
        "      \"h_max\": h_max\n",
        "    }\n",
        "\n",
        "\n",
        "  def load_state_dict(self, state_dict):\n",
        "    # for checkpoint saving\n",
        "    self._optimizer.load_state_dict(state_dict['sgd_state_dict'])\n",
        "    # for recover model internally if any numerical issue happens\n",
        "    param_id = 0\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group[\"params\"]:\n",
        "        p.data.copy_(state_dict[\"model_state_list\"][param_id] )\n",
        "        param_id += 1\n",
        "    self._global_state = state_dict['global_state']\n",
        "    self._lr_factor = state_dict['lr_factor']\n",
        "    self._iter = state_dict['iter']\n",
        "    self._lr = state_dict['lr']\n",
        "    self._mu = state_dict['mu']\n",
        "    self._clip_thresh = state_dict['clip_thresh']\n",
        "    self._beta = state_dict['beta']\n",
        "    self._curv_win_width = state_dict['curv_win_width']\n",
        "    self._zero_debias = state_dict['zero_debias']\n",
        "    self._h_min = state_dict[\"h_min\"]\n",
        "    self._h_max = state_dict[\"h_max\"]\n",
        "    return\n",
        "\n",
        "  def load_state_dict_perturb(self, state_dict):\n",
        "    # for checkpoint saving\n",
        "    self._optimizer.load_state_dict(state_dict['sgd_state_dict'])\n",
        "    # for recover model internally if any numerical issue happens\n",
        "    param_id = 0\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group[\"params\"]:\n",
        "        p.data.copy_(state_dict[\"model_state_list\"][param_id] )\n",
        "        p.data += 1e-8\n",
        "        param_id += 1\n",
        "    self._global_state = state_dict['global_state']\n",
        "    self._lr_factor = state_dict['lr_factor']\n",
        "    self._iter = state_dict['iter']\n",
        "    self._lr = state_dict['lr']\n",
        "    self._mu = state_dict['mu']\n",
        "    self._clip_thresh = state_dict['clip_thresh']\n",
        "    self._beta = state_dict['beta']\n",
        "    self._curv_win_width = state_dict['curv_win_width']\n",
        "    self._zero_debias = state_dict['zero_debias']\n",
        "    self._h_min = state_dict[\"h_min\"]\n",
        "    self._h_max = state_dict[\"h_max\"]\n",
        "    return\n",
        "\n",
        "\n",
        "  def set_lr_factor(self, factor):\n",
        "    self._lr_factor = factor\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_lr_factor(self):\n",
        "    return self._lr_factor\n",
        "\n",
        "\n",
        "  def zero_grad(self):\n",
        "    self._optimizer.zero_grad()\n",
        "    return\n",
        "\n",
        "\n",
        "  def zero_debias_factor(self):\n",
        "    return 1.0 - self._beta ** (self._iter + 1)\n",
        "\n",
        "\n",
        "  def zero_debias_factor_delay(self, delay):\n",
        "    # for exponentially averaged stat which starts at non-zero iter\n",
        "    return 1.0 - self._beta ** (self._iter - delay + 1)\n",
        "\n",
        "\n",
        "  def curvature_range(self):\n",
        "    global_state = self._global_state\n",
        "    if self._iter == 0:\n",
        "      global_state[\"curv_win\"] = torch.FloatTensor(self._curv_win_width, 1).zero_()\n",
        "    curv_win = global_state[\"curv_win\"]\n",
        "    grad_norm_squared = self._global_state[\"grad_norm_squared\"]\n",
        "    # curv_win[self._iter % self._curv_win_width] = np.log(grad_norm_squared + eps)\n",
        "    curv_win[self._iter % self._curv_win_width] = grad_norm_squared\n",
        "    valid_end = min(self._curv_win_width, self._iter + 1)\n",
        "    # we use running average over log scale, accelerating \n",
        "    # h_max / min in the begining to follow the varying trend of curvature.\n",
        "    beta = self._beta\n",
        "    if self._iter == 0:\n",
        "      global_state[\"h_min_avg\"] = 0.0\n",
        "      global_state[\"h_max_avg\"] = 0.0\n",
        "      self._h_min = 0.0\n",
        "      self._h_max = 0.0\n",
        "    if self._h_min_log_smooth:\n",
        "      global_state[\"h_min_avg\"] = \\\n",
        "          global_state[\"h_min_avg\"] * beta + (1 - beta) * torch.min(np.log(curv_win[:valid_end] + eps) )\n",
        "    else:\n",
        "      global_state[\"h_min_avg\"] = \\\n",
        "        global_state[\"h_min_avg\"] * beta + (1 - beta) * torch.min(curv_win[:valid_end] )\n",
        "    if self._h_max_log_smooth:\n",
        "      global_state[\"h_max_avg\"] = \\\n",
        "        global_state[\"h_max_avg\"] * beta + (1 - beta) * torch.max(np.log(curv_win[:valid_end] + eps) )\n",
        "    else:\n",
        "      global_state[\"h_max_avg\"] = \\\n",
        "        global_state[\"h_max_avg\"] * beta + (1 - beta) * torch.max(curv_win[:valid_end] )\n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "      if self._h_min_log_smooth:\n",
        "        self._h_min = np.exp(global_state[\"h_min_avg\"] / debias_factor)\n",
        "      else:\n",
        "        self._h_min = global_state[\"h_min_avg\"] / debias_factor\n",
        "      if self._h_max_log_smooth:\n",
        "        self._h_max = np.exp(global_state[\"h_max_avg\"] / debias_factor)\n",
        "      else:\n",
        "        self._h_max = global_state[\"h_max_avg\"] / debias_factor\n",
        "    else:\n",
        "      if self._h_min_log_smooth:\n",
        "        self._h_min = np.exp(global_state[\"h_min_avg\"] )\n",
        "      else:\n",
        "        self._h_min = global_state[\"h_min_avg\"]\n",
        "      if self._h_max_log_smooth:\n",
        "        self._h_max = np.exp(global_state[\"h_max_avg\"] )\n",
        "      else:\n",
        "        self._h_max = global_state[\"h_max_avg\"]\n",
        "    if self._sparsity_debias:\n",
        "      self._h_min *= self._sparsity_avg\n",
        "      self._h_max *= self._sparsity_avg\n",
        "    return\n",
        "\n",
        "\n",
        "  def grad_variance(self):\n",
        "    global_state = self._global_state\n",
        "    beta = self._beta\n",
        "    self._grad_var = np.array(0.0, dtype=np.float32)\n",
        "    for group_id, group in enumerate(self._optimizer.param_groups):\n",
        "      for p_id, p in enumerate(group['params'] ):\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        grad = p.grad.data\n",
        "        state = self._optimizer.state[p]\n",
        "        if self._iter == 0:\n",
        "          state[\"grad_avg\"] = grad.new().resize_as_(grad).zero_()\n",
        "          state[\"grad_avg_squared\"] = 0.0\n",
        "        state[\"grad_avg\"].mul_(beta).add_(1 - beta, grad)\n",
        "        self._grad_var += torch.sum(state[\"grad_avg\"] * state[\"grad_avg\"] ).item()\n",
        "        \n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "    else:\n",
        "      debias_factor = 1.0\n",
        "\n",
        "    self._grad_var /= -(debias_factor**2)\n",
        "    self._grad_var += global_state['grad_norm_squared_avg'].item() / debias_factor\n",
        "    # in case of negative variance: the two term are using different debias factors\n",
        "    self._grad_var = max(self._grad_var, eps)\n",
        "    if self._sparsity_debias:\n",
        "      self._grad_var *= self._sparsity_avg\n",
        "    return\n",
        "\n",
        "\n",
        "  def dist_to_opt(self):\n",
        "    global_state = self._global_state\n",
        "    beta = self._beta\n",
        "    if self._iter == 0:\n",
        "      global_state[\"grad_norm_avg\"] = 0.0\n",
        "      global_state[\"dist_to_opt_avg\"] = 0.0\n",
        "    global_state[\"grad_norm_avg\"] = \\\n",
        "      global_state[\"grad_norm_avg\"] * beta + (1 - beta) * math.sqrt(global_state[\"grad_norm_squared\"] )\n",
        "    global_state[\"dist_to_opt_avg\"] = \\\n",
        "      global_state[\"dist_to_opt_avg\"] * beta \\\n",
        "      + (1 - beta) * global_state[\"grad_norm_avg\"] / (global_state['grad_norm_squared_avg'] + eps)\n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "      self._dist_to_opt = global_state[\"dist_to_opt_avg\"] / debias_factor\n",
        "    else:\n",
        "      self._dist_to_opt = global_state[\"dist_to_opt_avg\"]\n",
        "    if self._sparsity_debias:\n",
        "      self._dist_to_opt /= (np.sqrt(self._sparsity_avg) + eps)\n",
        "    return\n",
        "\n",
        "\n",
        "  def grad_sparsity(self):\n",
        "    global_state = self._global_state\n",
        "    if self._iter == 0:\n",
        "      global_state[\"sparsity_avg\"] = 0.0\n",
        "    non_zero_cnt = 0.0\n",
        "    all_entry_cnt = 0.0\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        grad = p.grad.data\n",
        "        grad_non_zero = grad.nonzero()\n",
        "        if grad_non_zero.dim() > 0:\n",
        "          non_zero_cnt += grad_non_zero.size()[0]\n",
        "        all_entry_cnt += torch.numel(grad)\n",
        "    beta = self._beta\n",
        "    global_state[\"sparsity_avg\"] = beta * global_state[\"sparsity_avg\"] \\\n",
        "      + (1 - beta) * non_zero_cnt / float(all_entry_cnt)\n",
        "    self._sparsity_avg = \\\n",
        "      global_state[\"sparsity_avg\"] / self.zero_debias_factor()\n",
        "    \n",
        "    if self._verbose:\n",
        "      logging.debug(\"sparsity %f, sparsity avg %f\", non_zero_cnt / float(all_entry_cnt), self._sparsity_avg)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "  def lr_grad_norm_avg(self):\n",
        "    # this is for enforcing lr * grad_norm not \n",
        "    # increasing dramatically in case of instability.\n",
        "    #  Not necessary for basic use.\n",
        "    global_state = self._global_state\n",
        "    beta = self._beta\n",
        "    if \"lr_grad_norm_avg\" not in global_state:\n",
        "      global_state['grad_norm_squared_avg_log'] = 0.0\n",
        "    global_state['grad_norm_squared_avg_log'] = \\\n",
        "      global_state['grad_norm_squared_avg_log'] * beta \\\n",
        "      + (1 - beta) * np.log(global_state['grad_norm_squared'] + eps)\n",
        "    if \"lr_grad_norm_avg\" not in global_state:\n",
        "      global_state[\"lr_grad_norm_avg\"] = \\\n",
        "        0.0 * beta + (1 - beta) * np.log(self._lr * np.sqrt(global_state['grad_norm_squared'] ) + eps)\n",
        "      # we monitor the minimal smoothed ||lr * grad||\n",
        "      global_state[\"lr_grad_norm_avg_min\"] = \\\n",
        "        np.exp(global_state[\"lr_grad_norm_avg\"].cpu() / self.zero_debias_factor() )\n",
        "    else:\n",
        "      global_state[\"lr_grad_norm_avg\"] = global_state[\"lr_grad_norm_avg\"] * beta \\\n",
        "        + (1 - beta) * np.log(self._lr * np.sqrt(global_state['grad_norm_squared'] ) + eps)\n",
        "      global_state[\"lr_grad_norm_avg_min\"] = \\\n",
        "        min(global_state[\"lr_grad_norm_avg_min\"], \n",
        "            np.exp(global_state[\"lr_grad_norm_avg\"] / self.zero_debias_factor() ) )\n",
        "\n",
        "\n",
        "  def before_apply(self):\n",
        "    # compute running average of gradient and norm of gradient\n",
        "    beta = self._beta\n",
        "    global_state = self._global_state\n",
        "    if self._iter == 0:\n",
        "      global_state[\"grad_norm_squared_avg\"] = 0.0\n",
        "\n",
        "    global_state[\"grad_norm_squared\"] = 0.0\n",
        "    for group_id, group in enumerate(self._optimizer.param_groups):\n",
        "      for p_id, p in enumerate(group['params'] ):\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        grad = p.grad.data\n",
        "        param_grad_norm_squared = torch.sum(grad * grad)\n",
        "        global_state['grad_norm_squared'] += param_grad_norm_squared\n",
        "\n",
        "        if self._verbose:\n",
        "          logging.debug(\"Iteration  %f\", self._iter) \n",
        "          logging.debug(\"param grad squared gid %d, pid %d, %f, log scale: %f\", group_id, p_id, param_grad_norm_squared,\n",
        "            np.log(param_grad_norm_squared + 1e-10) / np.log(10) )   \n",
        "\n",
        "    if self._iter >= 1:\n",
        "      self._exploding_grad_clip_thresh = self._h_max\n",
        "      self._exploding_grad_clip_target_value = np.sqrt(self._h_max)    \n",
        "      if global_state['grad_norm_squared'].cpu() >= self._exploding_grad_clip_thresh:\n",
        "        self._exploding_grad_detected = True\n",
        "      else:\n",
        "        self._exploding_grad_detected = False\n",
        "\n",
        "  \n",
        "    global_state['grad_norm_squared_avg'] = \\\n",
        "      global_state['grad_norm_squared_avg'] * beta + (1 - beta) * global_state['grad_norm_squared']\n",
        "        \n",
        "    if self._verbose:\n",
        "      logging.debug(\"overall grad norm squared %f, log scale: %f\", \n",
        "        global_state['grad_norm_squared'], np.log(global_state['grad_norm_squared'] + 1e-10) / np.log(10))\n",
        "\n",
        "\n",
        "    if self._sparsity_debias:\n",
        "      self.grad_sparsity()\n",
        "\n",
        "    self.curvature_range()\n",
        "    self.grad_variance()\n",
        "    self.dist_to_opt()\n",
        "\n",
        "    if self._verbose:\n",
        "      logging.debug(\"h_max %f \", self._h_max)\n",
        "      logging.debug(\"h_min %f \", self._h_min)\n",
        "      logging.debug(\"dist %f \", self._dist_to_opt)\n",
        "      logging.debug(\"var %f \", self._grad_var)\n",
        "\n",
        "    if self._iter > 0:\n",
        "      self.get_mu()    \n",
        "      self.get_lr()\n",
        "\n",
        "      self._lr = beta * self._lr + (1 - beta) * self._lr_t\n",
        "      self._mu = beta * self._mu + (1 - beta) * self._mu_t\n",
        "\n",
        "      if self._verbose:\n",
        "        logging.debug(\"lr_t %f\", self._lr_t) \n",
        "        logging.debug(\"mu_t %f\", self._mu_t)\n",
        "        logging.debug(\"lr %f\", self._lr)\n",
        "        logging.debug(\"mu %f\", self._mu)\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_lr(self):\n",
        "    self._lr_t = (1.0 - math.sqrt(self._mu_t) )**2 / (self._h_min + eps)\n",
        "    # slow start of lr to prevent huge lr when there is only a few iteration finished\n",
        "    self._lr_t = min(self._lr_t, self._lr_t * (self._iter + 1) / float(10.0 * self._curv_win_width) )\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_cubic_root(self):\n",
        "    # We have the equation x^2 D^2 + (1-x)^4 * C / h_min^2\n",
        "    # where x = sqrt(mu).\n",
        "    # We substitute x, which is sqrt(mu), with x = y + 1.\n",
        "    # It gives y^3 + py = q\n",
        "    # where p = (D^2 h_min^2)/(2*C) and q = -p.\n",
        "    # We use the Vieta's substution to compute the root.\n",
        "    # There is only one real solution y (which is in [0, 1] ).\n",
        "    # http://mathworld.wolfram.com/VietasSubstitution.html\n",
        "    # eps in the numerator is to prevent momentum = 1 in case of zero gradient\n",
        "    if np.isnan(self._dist_to_opt.cpu()) or np.isnan(self._h_min.cpu()) or np.isnan(self._grad_var) \\\n",
        "      or np.isinf(self._dist_to_opt.cpu()) or np.isinf(self._h_min.cpu()) or np.isinf(self._grad_var):\n",
        "      logging.warning(\"Input to cubic solver has invalid nan/inf value!\")\n",
        "      raise Exception(\"Input to cubic solver has invalid nan/inf value!\")\n",
        "\n",
        "    p = (self._dist_to_opt + eps)**2 * (self._h_min + eps)**2 / 2 / (self._grad_var + eps)\n",
        "    w3 = (-math.sqrt(p**2 + 4.0 / 27.0 * p**3) - p) / 2.0\n",
        "    w = math.copysign(1.0, w3) * math.pow(math.fabs(w3), 1.0/3.0)\n",
        "    y = w - p / 3.0 / (w + eps)\n",
        "    x = y + 1\n",
        "\n",
        "    if self._verbose:\n",
        "      logging.debug(\"p %f, denominator %f\", p, self._grad_var + eps)\n",
        "      logging.debug(\"w3 %f \", w3)\n",
        "      logging.debug(\"y %f, denominator %f\", y, w + eps)\n",
        "\n",
        "    if np.isnan(x.cpu()) or np.isinf(x.cpu()):\n",
        "      logging.warning(\"Output from cubic is invalid nan/inf value!\")\n",
        "      raise Exception(\"Output from cubic is invalid nan/inf value!\")\n",
        "\n",
        "    return x.item()\n",
        "\n",
        "\n",
        "  def get_mu(self):\n",
        "    root = self.get_cubic_root()\n",
        "    dr = max( (self._h_max + eps) / (self._h_min + eps), 1.0 + eps)\n",
        "    self._mu_t = max(root**2, ( (np.sqrt(dr) - 1) / (np.sqrt(dr) + 1) )**2 )\n",
        "    return \n",
        "\n",
        "\n",
        "  def update_hyper_param(self):\n",
        "    for group in self._optimizer.param_groups:\n",
        "      group['momentum'] = self._mu_t\n",
        "      #group['momentum'] = max(self._mu, self._mu_t)\n",
        "      if self._force_non_inc_step == False:\n",
        "        group['lr'] = self._lr_t * self._lr_factor\n",
        "        # a loose clamping to prevent catastrophically large move. If the move\n",
        "        # is too large, we set lr to 0 and only use the momentum to move\n",
        "        if self._adapt_clip and (group['lr'] * np.sqrt(self._global_state['grad_norm_squared'].cpu()) >= self._catastrophic_move_thresh):\n",
        "          group['lr'] = self._catastrophic_move_thresh / np.sqrt(self._global_state['grad_norm_squared'] + eps)\n",
        "          if self._verbose:\n",
        "            logging.warning(\"clip catastropic move!\")\n",
        "      elif self._iter > self._curv_win_width:\n",
        "        # force to guarantee lr * grad_norm not increasing dramatically. \n",
        "        # Not necessary for basic use. Please refer to the comments\n",
        "        # in YFOptimizer.__init__ for more details\n",
        "        self.lr_grad_norm_avg()\n",
        "        debias_factor = self.zero_debias_factor()\n",
        "        group['lr'] = min(self._lr * self._lr_factor,\n",
        "          2.0 * self._global_state[\"lr_grad_norm_avg_min\"] \\\n",
        "          / (np.sqrt(np.exp(self._global_state['grad_norm_squared_avg_log'] / debias_factor) ) + eps) )\n",
        "    return\n",
        "\n",
        "\n",
        "  def auto_clip_thresh(self):\n",
        "    # Heuristic to automatically prevent sudden exploding gradient\n",
        "    # Not necessary for basic use.\n",
        "    return math.sqrt(self._h_max) * self._auto_clip_fac\n",
        "\n",
        "\n",
        "  def step(self):\n",
        "    # add weight decay\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "            continue\n",
        "        grad = p.grad.data\n",
        "\n",
        "        if group['weight_decay'] != 0:\n",
        "            grad = grad.add(group['weight_decay'], p.data)\n",
        "    \n",
        "    if self._clip_thresh != None:\n",
        "      torch.nn.utils.clip_grad_norm(self._var_list, self._clip_thresh)\n",
        "    elif (self._iter != 0 and self._auto_clip_fac != None):\n",
        "      # do not clip the first iteration\n",
        "      torch.nn.utils.clip_grad_norm(self._var_list, self.auto_clip_thresh() )\n",
        "\n",
        "    # loose threshold for preventing exploding gradients from destroying statistics\n",
        "    if self._adapt_clip and (self._iter > 1):\n",
        "      torch.nn.utils.clip_grad_norm(self._var_list, np.sqrt(self._stat_protect_fac * self._h_max) + eps)\n",
        "\n",
        "\n",
        "    try:\n",
        "      # before appply\n",
        "      self.before_apply()\n",
        "\n",
        "      # update learning rate and momentum\n",
        "      self.update_hyper_param()\n",
        "\n",
        "      # periodically save model and states\n",
        "      if self._iter % self._checkpoint_interval == 0:\n",
        "        if self._use_disk_checkpoint and os.path.exists(self._checkpoint_dir):\n",
        "          checkpoint_path = self._checkpoint_dir + \"/\" + self._checkpoint_file\n",
        "          with open(checkpoint_path, \"wb\") as f:\n",
        "            cp.dump(self.state_dict(), f, protocol=2)\n",
        "        else:\n",
        "          self._state_checkpoint = copy.deepcopy(self.state_dict() )\n",
        "      \n",
        "      # protection from exploding gradient\n",
        "      if self._exploding_grad_detected and self._verbose:\n",
        "        logging.warning(\"exploding gradient detected: grad norm detection thresh %f , grad norm %f, grad norm after clip%f\", \n",
        "          np.sqrt(self._exploding_grad_clip_thresh), \n",
        "          np.sqrt(self._global_state['grad_norm_squared'] ), \n",
        "          self._exploding_grad_clip_target_value)\n",
        "      if self._adapt_clip and self._exploding_grad_detected:\n",
        "        # print(\"exploding gradient detected: grad norm detection thresh \", np.sqrt(self._exploding_grad_clip_thresh), \n",
        "        #   \"grad norm\", np.sqrt(self._global_state['grad_norm_squared'] ), \n",
        "        #   \"grad norm after clip \", self._exploding_grad_clip_target_value)\n",
        "        torch.nn.utils.clip_grad_norm(self._var_list, self._exploding_grad_clip_target_value + eps)\n",
        "\n",
        "      self._optimizer.step()\n",
        "\n",
        "      self._iter += 1\n",
        "    except:\n",
        "      # load the last checkpoint\n",
        "      logging.warning(\"Numerical issue triggered restore with backup. Resuming from last checkpoint.\")\n",
        "      if self._use_disk_checkpoint and os.path.exists(self._checkpoint_dir):\n",
        "        checkpoint_path = self._checkpoint_dir + \"/\" + self._checkpoint_file\n",
        "        with open(checkpoint_path, \"rb\") as f:\n",
        "          self.load_state_dict_perturb(cp.load(f))\n",
        "      else:\n",
        "        self.load_state_dict_perturb(copy.deepcopy(self._state_checkpoint) )\n",
        "\n",
        "    return \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTI8VFHI9NU-",
        "colab_type": "text"
      },
      "source": [
        "# MAML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHUooGs7j0lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is modified from https://github.com/dragen1860/MAML-Pytorch and https://github.com/katerakelly/pytorch-maml \n",
        "\n",
        "class MAML(MetaTemplate):\n",
        "    def __init__(self, model_func,  n_way, n_support, approx = False):\n",
        "        super(MAML, self).__init__( model_func,  n_way, n_support, change_way = False)\n",
        "\n",
        "        self.loss_fn = CrossEntropyLoss()\n",
        "        self.classifier = Linear_fw(self.feat_dim, n_way)\n",
        "        self.classifier.bias.data.fill_(0)\n",
        "        # self.conv2d_fw = Conv2d_fw(self.)\n",
        "        self.n_task     = 4\n",
        "        self.task_update_num = 5\n",
        "        self.train_lr = 0.01\n",
        "        self.approx = approx #first order approx.        \n",
        "        # print(\"__init__MAML\")\n",
        "\n",
        "    def forward(self,x):\n",
        "#         print(\"forward_MAML_1\")\n",
        "        # print(\"MAML_forward_x.size() {}\".format(x.size()))\n",
        "        out  = self.feature.forward(x)\n",
        "        # print(\"MAML_forward_out.size() {}\".format(out.size()))\n",
        "        # writer.add_image('feature', out)\n",
        "        # print(\"forward_MAML_2\")\n",
        "        scores  = self.classifier.forward(out)\n",
        "        # print(\"MAML_forward_scores.size() {}\".format(scores.size()))\n",
        "#         writer.add_embedding(scores, metadata=None, label_img=None, global_step=0, tag='default',\n",
        "#                              metadata_header=None)\n",
        "#         # writer.add_image('classifier', scores)\n",
        "        # print(\"forward_MAML_3\")\n",
        "        return scores\n",
        "\n",
        "    def set_forward(self,x, is_feature = False):\n",
        "        assert is_feature == False, 'MAML do not support fixed feature' \n",
        "#         print(\"set_forward_MAML\")\n",
        "        x = x.cuda()\n",
        "        x_var = V(x)\n",
        "        \n",
        "        x_a_i = x_var[:,:self.n_support,:,:,:].contiguous().view( self.n_way* self.n_support, *x.size()[2:]) #support data \n",
        "        x_b_i = x_var[:,self.n_support:,:,:,:].contiguous().view( self.n_way* self.n_query,   *x.size()[2:]) #query data\n",
        "        y_a_i = V( torch.from_numpy( np.repeat(range( self.n_way ), self.n_support ) )).cuda() #label for support data\n",
        "        # print(\"x_var[:,:self.n_support,:,:,:].size() {}\".format(x_var[:,:self.n_support,:,:,:].size()))\n",
        "        # print(\"x_var[:,self.n_support:,:,:,:].size() {}\".format(x_var[:,self.n_support:,:,:,:].size()))\n",
        "        # print(\"x_a_i.size() {}\".format(x_a_i.size()))\n",
        "        # print(\"x_b_i.size() {}\".format(x_b_i.size()))\n",
        "#         global step__\n",
        "#         step__ = 1\n",
        "#         x_ = make_grid(x_a_i)\n",
        "#         writer.add_image('support_data', x_, step__)\n",
        "        \n",
        "#         y_ = make_grid(x_b_i)\n",
        "#         writer.add_image('query_data', y_, step__)\n",
        "        \n",
        "\n",
        "        \n",
        "        fast_parameters = list(self.parameters()) #the first gradient calcuated in line 45 is based on original weight\n",
        "        for weight in self.parameters():\n",
        "            weight.fast = None\n",
        "        self.zero_grad()\n",
        "\n",
        "        for task_step in range(self.task_update_num):\n",
        "#             print(\"set_forward_MAML_1\")\n",
        "            scores = self.forward(x_a_i)\n",
        "#             print(\"set_forward_MAML_2\")\n",
        "            set_loss = self.loss_fn( scores, y_a_i)\n",
        "#             print(\"set_forward_MAML_3\")\n",
        "            grad = torch.autograd.grad(set_loss, fast_parameters, create_graph=True, allow_unused=True) #build full graph support gradient of gradient\n",
        "#             print(\"set_forward_MAML_4\")\n",
        "            if self.approx:\n",
        "                grad = [ g.detach()  for g in grad ] #do not calculate gradient of gradient if using first order approximation\n",
        "#             print(\"set_forward_MAML_5\")\n",
        "            fast_parameters = []\n",
        "            for k, weight in enumerate(self.parameters()):\n",
        "                #for usage of weight.fast, please see Linear_fw, Conv_fw in backbone.py \n",
        "                # print(\"set_forward_MAML_6\")\n",
        "                if weight.fast is None:\n",
        "                    weight.fast = weight - self.train_lr * grad[k] #create weight.fast \n",
        "                else:\n",
        "                    weight.fast = weight.fast - self.train_lr * grad[k] #create an updated weight.fast, note the '-' is not merely minus value, but to create a new weight.fast \n",
        "                fast_parameters.append(weight.fast) #gradients calculated in line 45 are based on newest fast weight, but the graph will retain the link to old weight.fasts\n",
        "        global step_\n",
        "        step_ += 1\n",
        "        # writer.add_histogram('weight.fast', weight.fast, step_)\n",
        "        # print(\"set_forward_MAML______\")\n",
        "        scores = self.forward(x_b_i)\n",
        "        return scores\n",
        "\n",
        "    def set_forward_adaptation(self,x, is_feature = False): #overwrite parrent function\n",
        "#         print(\"set_forward_adaptation_MAML\")\n",
        "        raise ValueError('MAML performs further adapation simply by increasing task_upate_num')\n",
        "\n",
        "\n",
        "    def set_forward_loss(self, x):\n",
        "#         print(\"set_forward_loss_MAML\")\n",
        "        scores = self.set_forward(x, is_feature = False)\n",
        "        y_b_i = V( torch.from_numpy( np.repeat(range( self.n_way ), self.n_query   ) )).cuda()\n",
        "        loss = self.loss_fn(scores, y_b_i)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train_loop(self, epoch, train_loader, optimizer): #overwrite parrent function\n",
        "        print_freq = 10\n",
        "        avg_loss=0\n",
        "        task_count = 0\n",
        "        loss_all = []\n",
        "        optimizer.zero_grad()\n",
        "        scheduler = CyclicCosAnnealingLR(optimizer, milestones=[10,25,60,80,120,180,240,320,400,480],\n",
        "                                         decay_milestones=[60, 120, 240, 480, 960], eta_min=1e-6)\n",
        "\n",
        "#         print(\"train_loop_MAML\")\n",
        "        \n",
        "        #train\n",
        "        for i, (x,_) in enumerate(train_loader):\n",
        "            scheduler.step()\n",
        "            self.n_query = x.size(1) - self.n_support\n",
        "#             print(\"x.size() {}\".format(x.size()))\n",
        "#             print(\"n_query {}\".format(self.n_query))\n",
        "#             print(\"x.size(1) {}\".format(x.size(1)))\n",
        "#             print(\"n_support {}\".format(self.n_support))\n",
        "            assert self.n_way  ==  x.size(0), \"MAML do not support way change\"\n",
        "\n",
        "            loss = self.set_forward_loss(x)\n",
        "            # print('loss.shape', loss.shape)\n",
        "            avg_loss = avg_loss+loss.item()\n",
        "            # print('avg_loss', avg_loss.shape)\n",
        "            loss_all.append(loss)\n",
        "            # print('loss_all.shape', loss_all.shape)\n",
        "            task_count += 1\n",
        "#             print(\"task_count {}\".format(task_count))\n",
        "#             print('task_count', task_count)\n",
        "            if task_count == self.n_task: #MAML update several tasks at one time\n",
        "                loss_q = torch.stack(loss_all).sum(0)\n",
        "                loss_q.backward()\n",
        "\n",
        "                optimizer.step()\n",
        "                task_count = 0\n",
        "                loss_all = []\n",
        "            optimizer.zero_grad()\n",
        "            # %debug\n",
        "            if i % print_freq==0:\n",
        "                print('Epoch {:d} | Batch {:d}/{:d} | Loss {:f}'.format(epoch, i, len(train_loader), avg_loss/float(i+1)))\n",
        "                writer.add_scalar('loss_epoch_', avg_loss/float(i+1), epoch)\n",
        "                      \n",
        "    def test_loop(self, test_loader, return_std = False): #overwrite parrent function\n",
        "        correct =0\n",
        "        count = 0\n",
        "        acc_all = []\n",
        "#         print(\"test_loop_MAML\")\n",
        "        iter_num = len(test_loader) \n",
        "        for i, (x,_) in enumerate(test_loader):\n",
        "            self.n_query = x.size(1) - self.n_support\n",
        "            assert self.n_way  ==  x.size(0), \"MAML do not support way change\"\n",
        "            correct_this, count_this = self.correct(x)\n",
        "            acc_all.append(correct_this/ count_this *100 )\n",
        "\n",
        "        acc_all  = np.asarray(acc_all)\n",
        "        acc_mean = np.mean(acc_all)\n",
        "        acc_std  = np.std(acc_all)\n",
        "        print('%d Test Acc = %4.2f%% +- %4.2f%%' %(iter_num,  acc_mean, 1.96* acc_std/np.sqrt(iter_num)))\n",
        "        if return_std:\n",
        "            return acc_mean, acc_std\n",
        "        else:\n",
        "            return acc_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwViFe-k9PeM",
        "colab_type": "text"
      },
      "source": [
        "# RelationNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaDYJTRbI3AB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "class RelationNet(MetaTemplate):\n",
        "    def __init__(self, model_func,  n_way, n_support, loss_type = 'mse'):\n",
        "        super(RelationNet, self).__init__(model_func,  n_way, n_support)\n",
        "        \n",
        "        print(\"RelationNet__init__\")\n",
        "        self.loss_type = loss_type  #'softmax'# 'mse'\n",
        "        self.relation_module = RelationModule( self.feat_dim , 8, self.loss_type ) #relation net features are not pooled, so self.feat_dim is [dim, w, h] \n",
        "\n",
        "        if self.loss_type == 'mse':\n",
        "            self.loss_fn = MSELoss()  \n",
        "        else:\n",
        "            self.loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    def set_forward(self,x,is_feature = False):\n",
        "        print(\"RelationNet__set_forward_x.size() {}\".format(x.size()))\n",
        "        z_support, z_query  = self.parse_feature(x,is_feature)\n",
        "        print(\"RelationNet__set_forward__\")\n",
        "        z_support   = z_support.contiguous()\n",
        "        z_proto     = z_support.view( self.n_way, self.n_support, *self.feat_dim ).mean(1) \n",
        "        z_query     = z_query.contiguous().view( self.n_way* self.n_query, *self.feat_dim )\n",
        "\n",
        "        \n",
        "        z_proto_ext = z_proto.unsqueeze(0).repeat(self.n_query* self.n_way,1,1,1,1)\n",
        "        z_query_ext = z_query.unsqueeze(0).repeat( self.n_way,1,1,1,1)\n",
        "        z_query_ext = torch.transpose(z_query_ext,0,1)\n",
        "        extend_final_feat_dim = self.feat_dim.copy()\n",
        "        extend_final_feat_dim[0] *= 2\n",
        "        relation_pairs = torch.cat((z_proto_ext,z_query_ext),2).view(-1, *extend_final_feat_dim)\n",
        "        relations = self.relation_module(relation_pairs).view(-1, self.n_way)\n",
        "\n",
        "        return relations\n",
        "\n",
        "    def set_forward_adaptation(self,x,is_feature = True): #overwrite parent function\n",
        "        assert is_feature == True, 'Finetune only support fixed feature' \n",
        "        print(\"RelationNet__set_forward_adaptation__\")\n",
        "        full_n_support = self.n_support\n",
        "        full_n_query = self.n_query\n",
        "        relation_module_clone = RelationModule( self.feat_dim , 8, self.loss_type )\n",
        "        relation_module_clone.load_state_dict(self.relation_module.state_dict())\n",
        "        z_support, z_query  = self.parse_feature(x,is_feature)\n",
        "        z_support   = z_support.contiguous()\n",
        "        set_optimizer = SGD(self.relation_module.parameters(), lr = 0.01, momentum=0.9, dampening=0.9, weight_decay=0.001)\n",
        "\n",
        "        self.n_support = 3\n",
        "        self.n_query = 2\n",
        "\n",
        "        z_support_cpu = z_support.data.cpu().numpy()\n",
        "        for epoch in range(100):\n",
        "            perm_id = np.random.permutation(full_n_support).tolist()            \n",
        "            sub_x = np.array([z_support_cpu[i,perm_id,:,:,:] for i in range(z_support.size(0))])\n",
        "            sub_x = torch.Tensor(sub_x).cuda()\n",
        "            if self.change_way:\n",
        "                self.n_way  = sub_x.size(0)\n",
        "            set_optimizer.zero_grad()\n",
        "            y = torch.from_numpy(np.repeat(range( self.n_way ), self.n_query ))\n",
        "            scores = self.set_forward(sub_x, is_feature = True)\n",
        "            if self.loss_type == 'mse':\n",
        "                y_oh = one_hot(y, self.n_way)\n",
        "                y_oh = V(y_oh.cuda())            \n",
        "\n",
        "                loss =  self.loss_fn(scores, y_oh )\n",
        "            else:\n",
        "                y = V(y.cuda())\n",
        "                loss = self.loss_fn(scores, y )\n",
        "            loss.backward()\n",
        "            set_optimizer.step()\n",
        "\n",
        "        self.n_support = full_n_support\n",
        "        self.n_query = full_n_query\n",
        "        z_proto     = z_support.view( self.n_way, self.n_support, *self.feat_dim ).mean(1) \n",
        "        z_query     = z_query.contiguous().view( self.n_way* self.n_query, *self.feat_dim )\n",
        "\n",
        "        \n",
        "        z_proto_ext = z_proto.unsqueeze(0).repeat(self.n_query* self.n_way,1,1,1,1)\n",
        "        z_query_ext = z_query.unsqueeze(0).repeat( self.n_way,1,1,1,1)\n",
        "        z_query_ext = torch.transpose(z_query_ext,0,1)\n",
        "        extend_final_feat_dim = self.feat_dim.copy()\n",
        "        extend_final_feat_dim[0] *= 2\n",
        "        relation_pairs = torch.cat((z_proto_ext,z_query_ext),2).view(-1, *extend_final_feat_dim)\n",
        "        relations = self.relation_module(relation_pairs).view(-1, self.n_way)\n",
        "\n",
        "        self.relation_module.load_state_dict(relation_module_clone.state_dict())\n",
        "        return relations\n",
        "    def set_forward_loss(self, x):\n",
        "      \n",
        "        y = torch.from_numpy(np.repeat(range( self.n_way ), self.n_query ))\n",
        "        print(\"RelationNet__set_forward_loss__\")\n",
        "        scores = self.set_forward(x)\n",
        "        if self.loss_type == 'mse':\n",
        "            y_oh = one_hot(y, self.n_way)\n",
        "            y_oh = V(y_oh.cuda())            \n",
        "\n",
        "            return self.loss_fn(scores, y_oh )\n",
        "        else:\n",
        "            y = V(y.cuda())\n",
        "            return self.loss_fn(scores, y )\n",
        "\n",
        "class RelationConvBlock(Module):\n",
        "    def __init__(self, indim, outdim, padding = 0):\n",
        "        super(RelationConvBlock, self).__init__()\n",
        "        self.indim  = indim\n",
        "        self.outdim = outdim\n",
        "        self.C      = Conv2d(indim, outdim, 3, padding = padding )\n",
        "        self.BN     = BatchNorm2d(outdim, momentum=1, affine=True)\n",
        "        self.relu   = ReLU()\n",
        "        self.pool   = MaxPool2d(2)\n",
        "        print(\"RelationConvBlock__init__\")\n",
        "        self.parametrized_layers = [self.C, self.BN, self.relu, self.pool]\n",
        "\n",
        "        for layer in self.parametrized_layers:\n",
        "            init_layer(layer)\n",
        "\n",
        "        self.trunk = Sequential(*self.parametrized_layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        print(\"RelationConvBlock__forward__x.size() {}\".format(x.size()))\n",
        "        out = self.trunk(x)\n",
        "        print(\"RelationConvBlock__forward__out.size() {}\".format(out.size()))\n",
        "        return out\n",
        "\n",
        "class RelationModule(Module):\n",
        "    \"\"\"docstring for RelationNetwork\"\"\"\n",
        "    def __init__(self,input_size,hidden_size, loss_type = 'mse'):        \n",
        "        super(RelationModule, self).__init__()\n",
        "        print(\"RelationModule__init__\")\n",
        "        self.loss_type = loss_type\n",
        "        padding = 1 if ( input_size[1] <10 ) and ( input_size[2] <10 ) else 0 # when using Resnet, conv map without avgpooling is 7x7, need padding in block to do pooling\n",
        "\n",
        "        self.layer1 = RelationConvBlock(input_size[0]*2, input_size[0], padding = padding )\n",
        "        self.layer2 = RelationConvBlock(input_size[0], input_size[0], padding = padding )\n",
        "\n",
        "        shrink_s = lambda s: int((int((s- 2 + 2*padding)/2)-2 + 2*padding)/2)\n",
        "\n",
        "        self.fc1 = Linear( input_size[0]* shrink_s(input_size[1]) * shrink_s(input_size[2]), hidden_size )\n",
        "        self.fc2 = Linear( hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        print(\"RelationModule__forward__x.size() {}\".format(x.size()))\n",
        "        out = self.layer1(x)\n",
        "        print(\"RelationModule__forward__out_layer1.size() {}\".format(out.size()))\n",
        "        out = self.layer2(out)\n",
        "        print(\"RelationModule__forward__out_layer2.size() {}\".format(out.size()))\n",
        "        out = out.view(out.size(0),-1)\n",
        "        print(\"RelationModule__forward__out_layer2_view.size() {}\".format(out.size()))\n",
        "        out = F.relu(self.fc1(out))\n",
        "        print(\"RelationModule__forward__out_fc1_relu.size() {}\".format(out.size()))\n",
        "        if self.loss_type == 'mse':\n",
        "            out = F.sigmoid(self.fc2(out))\n",
        "            print(\"RelationModule__forward__out_fc2_sigmoid.size() {}\".format(out.size()))\n",
        "        elif self.loss_type == 'softmax':\n",
        "            out = self.fc2(out)\n",
        "            print(\"RelationModule__forward__out_fc2.size() {}\".format(out.size()))\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crr81jK89SfG",
        "colab_type": "text"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f643faae-4cc1-4ed8-f180-7d901e01960c",
        "id": "FiT5oIuNYRDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "def train(base_loader, val_loader, model, optimization, start_epoch, stop_epoch, params):    \n",
        "    if optimization == 'Adam':\n",
        "        optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
        "        # optimizer = YFOptimizer(net.parameters(), lr=0.0001, mu=0, weight_decay=5e-4)\n",
        "\n",
        "#         scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=self.args.total_epochs,\n",
        "#                                                               eta_min=self.args.min_learning_rate)\n",
        "        \n",
        "\n",
        "    elif optimization == 'SGD':\n",
        "        optimizer = SGD(model.parameters())\n",
        "        \n",
        "    # raise ValueError('Unknown optimization, please define by yourself')\n",
        "    # tw.draw_model(model, np.zeros(25, 3, 84, 84).to(device))\n",
        "    # tw.model_stats(model, np.zeros(25, 3, 84, 84).to(device))\n",
        "    # summary(model, torch.zeros(25, 3, 84, 84).to(device))\n",
        "#     flops, params = profile(model, input_size=(25, 3, 84, 84))\n",
        "#     print('flops', flops)\n",
        "#     print('params', params)\n",
        "    # writer.add_graph(model, (torch.rand(25, 3, 84, 84).to(device),))\n",
        "    # writer.add_graph()\n",
        "    max_acc = 0       \n",
        "    print(\"train!!!\")\n",
        "    for epoch in range(start_epoch,stop_epoch):\n",
        "        model.train()\n",
        "        print(\"train_\")\n",
        "        model.train_loop(epoch, base_loader,  optimizer ) #model are called by reference, no need to return \n",
        "        print(\"train__\")\n",
        "        model.eval()\n",
        "        print(\"train___\")\n",
        "        if not os.path.isdir(params.checkpoint_dir):\n",
        "            os.makedirs(params.checkpoint_dir)\n",
        "        # %debug\n",
        "        acc = model.test_loop( val_loader)\n",
        "        if acc > max_acc : #for baseline and baseline++, we don't use validation here so we let acc = -1\n",
        "            print(\"best model! save...\")\n",
        "            max_acc = acc\n",
        "            outfile = os.path.join(params.checkpoint_dir, 'best_model.tar')\n",
        "            # print(outfile)\n",
        "            # print(epoch)\n",
        "            torch.save({'epoch':epoch, 'state':model.state_dict()}, outfile)\n",
        "\n",
        "        if (epoch % params.save_freq==0) or (epoch==stop_epoch-1):\n",
        "            outfile = os.path.join(params.checkpoint_dir, '{:d}.tar'.format(epoch))\n",
        "            torch.save({'epoch':epoch, 'state':model.state_dict()}, outfile)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "np.random.seed(10)\n",
        "script = 'train'\n",
        "\n",
        "parser = argparse.ArgumentParser(description= 'few-shot script %s' %(script))\n",
        "parser.add_argument('--dataset'     , default='mouimoto',        help='CUB/miniImagenet/cross/omniglot/cross_char')\n",
        "parser.add_argument('--model'       , default='Conv4',      help='model: Conv{4|6} / ResNet{10|18|34|50|101}') # 50 and 101 are not used in the paper\n",
        "parser.add_argument('--method'      , default='maml',   help='baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}') #relationnet_softmax replace L2 norm with softmax to expedite training, maml_approx use first-order approximation in the gradient for efficiency\n",
        "parser.add_argument('--train_n_way' , default=5, type=int,  help='class num to classify for training') #baseline and baseline++ would ignore this parameter\n",
        "parser.add_argument('--test_n_way'  , default=5, type=int,  help='class num to classify for testing (validation) ') #baseline and baseline++ only use this parameter in finetuning\n",
        "parser.add_argument('--n_shot'      , default=5, type=int,  help='number of labeled data in each class, same as n_support') #baseline and baseline++ only use this parameter in finetuning\n",
        "parser.add_argument('--train_aug'   , action='store_true',  help='perform data augmentation or not during training ') #still required for save_features.py and test.py to find the model path correctly\n",
        "\n",
        "if script == 'train':\n",
        "    parser.add_argument('--num_classes' , default=98, type=int, help='total number of classes in softmax, only used in baseline') #make it larger than the maximum label value in base class\n",
        "    parser.add_argument('--save_freq'   , default=50, type=int, help='Save frequency')\n",
        "    parser.add_argument('--start_epoch' , default=0, type=int,help ='Starting epoch')\n",
        "    parser.add_argument('--stop_epoch'  , default=-1, type=int, help ='Stopping epoch') #for meta-learning methods, each epoch contains 100 episodes. The default epoch number is dataset dependent. See train.py\n",
        "    parser.add_argument('--resume'      , action='store_true', help='continue from previous trained model with largest epoch')\n",
        "    parser.add_argument('--warmup'      , action='store_true', help='continue from baseline, neglected if resume is true') #never used in the paper\n",
        "elif script == 'save_features':\n",
        "    parser.add_argument('--split'       , default='novel', help='base/val/novel') #default novel, but you can also test base/val class accuracy if you want \n",
        "    parser.add_argument('--save_iter', default=-1, type=int,help ='save feature from the model trained in x epoch, use the best model if x is -1')\n",
        "elif script == 'test':\n",
        "    parser.add_argument('--split'       , default='novel', help='base/val/novel') #default novel, but you can also test base/val class accuracy if you want \n",
        "    parser.add_argument('--save_iter', default=-1, type=int,help ='saved feature from the model trained in x epoch, use the best model if x is -1')\n",
        "    parser.add_argument('--adaptation'  , action='store_true', help='further adaptation in test time or not')\n",
        "else:\n",
        "   raise ValueError('Unknown script')\n",
        "\n",
        "params = parser.parse_args('')\n",
        "\n",
        "\n",
        "if params.dataset == 'cross':\n",
        "    base_file = data_dir['miniImagenet'] + 'all.json' \n",
        "    val_file   = data_dir['CUB'] + 'val.json' \n",
        "elif params.dataset == 'cross_char':\n",
        "    base_file = data_dir['omniglot'] + 'noLatin.json' \n",
        "    val_file   = data_dir['emnist'] + 'val.json' \n",
        "else:\n",
        "    base_file = data_dir[params.dataset] + 'base.json' \n",
        "    val_file   = data_dir[params.dataset] + 'val.json' \n",
        "\n",
        "if 'Conv' in params.model:\n",
        "    if params.dataset in ['omniglot', 'cross_char']:\n",
        "        image_size = 28\n",
        "    else:\n",
        "        image_size = 84\n",
        "else:\n",
        "    image_size = 224\n",
        "\n",
        "if params.dataset in ['omniglot', 'cross_char']:\n",
        "    assert params.model == 'Conv4' and not params.train_aug ,'omniglot only support Conv4 without augmentation'\n",
        "    params.model = 'Conv4S'\n",
        "\n",
        "optimization = 'Adam'\n",
        "\n",
        "if params.stop_epoch == -1: \n",
        "    if params.method in ['baseline', 'baseline++'] :\n",
        "        if params.dataset in ['omniglot', 'cross_char']:\n",
        "            params.stop_epoch = 5\n",
        "        elif params.dataset in ['CUB']:\n",
        "            params.stop_epoch = 200 # This is different as stated in the open-review paper. However, using 400 epoch in baseline actually lead to over-fitting\n",
        "        elif params.dataset in ['miniImagenet', 'cross']:\n",
        "            params.stop_epoch = 400\n",
        "        else:\n",
        "            params.stop_epoch = 400 #default\n",
        "    else: #meta-learning methods\n",
        "        if params.n_shot == 1:\n",
        "            params.stop_epoch = 600\n",
        "        elif params.n_shot == 5:\n",
        "            params.stop_epoch = 400\n",
        "        else:\n",
        "            params.stop_epoch = 600 #default\n",
        "\n",
        "\n",
        "if params.method in ['baseline', 'baseline++'] :\n",
        "    base_datamgr    = SimpleDataManager(image_size, batch_size = 16)\n",
        "    base_loader     = base_datamgr.get_data_loader( base_file , aug = params.train_aug )\n",
        "    val_datamgr     = SimpleDataManager(image_size, batch_size = 64)\n",
        "    val_loader      = val_datamgr.get_data_loader( val_file, aug = False)\n",
        "\n",
        "    if params.dataset == 'omniglot':\n",
        "        assert params.num_classes >= 4112, 'class number need to be larger than max label id in base class'\n",
        "    if params.dataset == 'cross_char':\n",
        "        assert params.num_classes >= 1597, 'class number need to be larger than max label id in base class'\n",
        "\n",
        "    if params.method == 'baseline':\n",
        "        model           = BaselineTrain( model_dict[params.model], params.num_classes)\n",
        "    elif params.method == 'baseline++':\n",
        "        model           = BaselineTrain( model_dict[params.model], params.num_classes, loss_type = 'dist')\n",
        "\n",
        "elif params.method in ['protonet','matchingnet','relationnet', 'relationnet_softmax', 'maml', 'maml_approx']:\n",
        "    n_query = max(1, int(16* params.test_n_way/params.train_n_way)) #if test_n_way is smaller than train_n_way, reduce n_query to keep batch size small\n",
        "\n",
        "    train_few_shot_params    = dict(n_way = params.train_n_way, n_support = params.n_shot) \n",
        "    base_datamgr            = SetDataManager(image_size, n_query = n_query,  **train_few_shot_params)\n",
        "    base_loader             = base_datamgr.get_data_loader( base_file , aug = params.train_aug )\n",
        "\n",
        "    test_few_shot_params     = dict(n_way = params.test_n_way, n_support = params.n_shot) \n",
        "    val_datamgr             = SetDataManager(image_size, n_query = n_query, **test_few_shot_params)\n",
        "    val_loader              = val_datamgr.get_data_loader( val_file, aug = False) \n",
        "    #a batch for SetDataManager: a [n_way, n_support + n_query, dim, w, h] tensor        \n",
        "    \n",
        "    if params.method == 'protonet':\n",
        "        model           = ProtoNet( model_dict[params.model], **train_few_shot_params )\n",
        "    elif params.method == 'matchingnet':\n",
        "        model           = MatchingNet( model_dict[params.model], **train_few_shot_params )\n",
        "    elif params.method in ['relationnet', 'relationnet_softmax']:\n",
        "        if params.model == 'Conv4': \n",
        "            feature_model = Conv4NP\n",
        "        elif params.model == 'Conv6': \n",
        "            feature_model = Conv6NP\n",
        "        elif params.model == 'Conv4S': \n",
        "            feature_model = Conv4SNP\n",
        "        else:\n",
        "            feature_model = lambda: model_dict[params.model]( flatten = False )\n",
        "        loss_type = 'mse' if params.method == 'relationnet' else 'softmax'\n",
        "\n",
        "        model           = RelationNet( feature_model, loss_type = loss_type , **train_few_shot_params )\n",
        "    elif params.method in ['maml' , 'maml_approx']:\n",
        "        ConvBlock.maml = True\n",
        "        # SimpleBlock.maml = True\n",
        "        # BottleneckBlock.maml = True\n",
        "        # ResNet.maml = True\n",
        "        model           = MAML(  model_dict[params.model], approx = (params.method == 'maml_approx') , **train_few_shot_params )\n",
        "        if params.dataset in ['omniglot', 'cross_char']: #maml use different parameter in omniglot\n",
        "            model.n_task     = 32\n",
        "            model.task_update_num = 1\n",
        "            model.train_lr = 0.1\n",
        "else:\n",
        "   raise ValueError('Unknown method')\n",
        "\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "params.checkpoint_dir = '%s/checkpoints/%s/%s_%s' %(save_dir, params.dataset, params.model, params.method)\n",
        "if params.train_aug:\n",
        "    params.checkpoint_dir += '_aug'\n",
        "if not params.method  in ['baseline', 'baseline++']: \n",
        "    params.checkpoint_dir += '_%dway_%dshot' %( params.train_n_way, params.n_shot)\n",
        "\n",
        "print(params.checkpoint_dir)\n",
        "if not os.path.isdir(params.checkpoint_dir):\n",
        "    os.makedirs(params.checkpoint_dir)\n",
        "\n",
        "start_epoch = params.start_epoch\n",
        "stop_epoch = params.stop_epoch\n",
        "if params.method == 'maml' or params.method == 'maml_approx' :\n",
        "    stop_epoch = params.stop_epoch * model.n_task #maml use multiple tasks in one update \n",
        "\n",
        "params.resume = True\n",
        "print(params.resume)\n",
        "if params.resume:\n",
        "    resume_file = get_resume_file(params.checkpoint_dir)\n",
        "    if resume_file is not None:\n",
        "        print(resume_file)\n",
        "        tmp = torch.load(resume_file)\n",
        "        start_epoch = tmp['epoch']+1\n",
        "        model.load_state_dict(tmp['state'])\n",
        "elif params.warmup: #We also support warmup from pretrained baseline feature, but we never used in our paper\n",
        "    baseline_checkpoint_dir = '%s/checkpoints/%s/%s_%s' %(save_dir, params.dataset, params.model, 'baseline')\n",
        "    if params.train_aug:\n",
        "        baseline_checkpoint_dir += '_aug'\n",
        "    warmup_resume_file = get_resume_file(baseline_checkpoint_dir)\n",
        "    tmp = torch.load(warmup_resume_file)\n",
        "    if tmp is not None: \n",
        "        state = tmp['state']\n",
        "        state_keys = list(state.keys())\n",
        "        for i, key in enumerate(state_keys):\n",
        "            if \"feature.\" in key:\n",
        "                newkey = key.replace(\"feature.\",\"\")  # an archit4/ZgFhht78gNlBK2aM5PIVJwEUyYuJG6zSMSz54EPSp6KVgWzRnc2FHMs4/ZgFhht78gNlBK2aM5PIVJwEUyYuJG6zSMSz54EPSp6KVgWzRnc2FHMsecture model has attribute 'feature', load architecture feature to backbone by casting name from 'feature.trunk.xx' to 'trunk.xx'  \n",
        "                state[newkey] = state.pop(key)\n",
        "            else:\n",
        "                state.pop(key)\n",
        "        model.feature.load_state_dict(state)\n",
        "    else:\n",
        "        raise ValueError('No warm_up file')\n",
        "\n",
        "%debug\n",
        "model = train(base_loader, val_loader,  model, optimization, start_epoch, stop_epoch, params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(4)\n",
            "/gdrive/My Drive/few_shot/save_dir_mouimoto/checkpoints/mouimoto/Conv4_maml_5way_5shot\n",
            "True\n",
            "/gdrive/My Drive/few_shot/save_dir_mouimoto/checkpoints/mouimoto/Conv4_maml_5way_5shot/0.tar\n",
            "> \u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m(490)\u001b[0;36m_save\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    488 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    489 \u001b[0;31m                \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 490 \u001b[0;31m                    \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    491 \u001b[0;31m                    \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    492 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR2daGeUN2b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /gdrive/My\\ Drive/mouimoto/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69z6WXIvs-dn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# trace the model\n",
        "devices = [':{}'.format(n) for n in range(0, num_cores)]\n",
        "inputs = torch.zeros(batch_size, 1, 28, 28)\n",
        "target = torch.zeros(batch_size, dtype=torch.int64)\n",
        "xla_model = xm.XlaModel(model, [inputs], loss_fn=F.nll_loss, target=target, num_cores=num_cores, devices=devices)\n",
        "optimizer = optim.SGD(xla_model.parameters_list(), lr=lr, momentum=momentum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_2dwWUss-cf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "log_fn = xm.get_log_fn()\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  xla_model.train(train_loader, optimizer, batch_size, log_interval=log_interval, metrics_debug=False,\n",
        "                  log_fn=log_fn)\n",
        "  accuracy = xla_model.test(test_loader, xm.category_eval_fn(F.nll_loss), batch_size, log_fn=log_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb2Uc9nsUJ6m",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "def feature_evaluation(cl_data_file, model, n_way = 5, n_support = 5, n_query = 15, adaptation = False):\n",
        "    class_list = cl_data_file.keys()\n",
        "\n",
        "    select_class = random.sample(class_list,n_way)\n",
        "    z_all  = []\n",
        "    for cl in select_class:\n",
        "        img_feat = cl_data_file[cl]\n",
        "        perm_ids = np.random.permutation(len(img_feat)).tolist()\n",
        "        z_all.append( [ np.squeeze( img_feat[perm_ids[i]]) for i in range(n_support+n_query) ] )     # stack each batch\n",
        "\n",
        "    z_all = torch.from_numpy(np.array(z_all) )\n",
        "    model.n_query = n_query\n",
        "    if adaptation:\n",
        "        scores  = model.set_forward_adaptation(z_all, is_feature = True)\n",
        "    else:\n",
        "        scores  = model.set_forward(z_all, is_feature = True)\n",
        "    pred = scores.data.cpu().numpy().argmax(axis = 1)\n",
        "    y = np.repeat(range( n_way ), n_query )\n",
        "    acc = np.mean(pred == y)*100 \n",
        "    return acc\n",
        "\n",
        "\n",
        "params = parser.parse_args('')\n",
        "\n",
        "params.save_iter = -1\n",
        "params.split = 'novel'\n",
        "params.adaptation = True\n",
        "acc_all = []\n",
        "\n",
        "iter_num = 600\n",
        "\n",
        "few_shot_params = dict(n_way = params.test_n_way , n_support = params.n_shot) \n",
        "\n",
        "if params.dataset in ['omniglot', 'cross_char']:\n",
        "    assert params.model == 'Conv4' and not params.train_aug ,'omniglot only support Conv4 without augmentation'\n",
        "    params.model = 'Conv4S'\n",
        "\n",
        "if params.method == 'baseline':\n",
        "    model           = BaselineFinetune( model_dict[params.model], **few_shot_params )\n",
        "elif params.method == 'baseline++':\n",
        "    model           = BaselineFinetune( model_dict[params.model], loss_type = 'dist', **few_shot_params )\n",
        "elif params.method == 'protonet':\n",
        "    model           = ProtoNet( model_dict[params.model], **few_shot_params )\n",
        "elif params.method == 'matchingnet':\n",
        "    model           = MatchingNet( model_dict[params.model], **few_shot_params )\n",
        "elif params.method in ['relationnet', 'relationnet_softmax']:\n",
        "    if params.model == 'Conv4': \n",
        "        feature_model = Conv4NP\n",
        "    elif params.model == 'Conv6': \n",
        "        feature_model = Conv6NP\n",
        "    elif params.model == 'Conv4S': \n",
        "        feature_model = Conv4SNP\n",
        "    else:\n",
        "        feature_model = lambda: model_dict[params.model]( flatten = False )\n",
        "    loss_type = 'mse' if params.method == 'relationnet' else 'softmax'\n",
        "    model           = RelationNet( feature_model, loss_type = loss_type , **few_shot_params )\n",
        "elif params.method in ['maml' , 'maml_approx']:\n",
        "    ConvBlock.maml = True\n",
        "    SimpleBlock.maml = True\n",
        "    # BottleneckBlock.maml = True\n",
        "    # ResNet.maml = True\n",
        "    model = MAML(  model_dict[params.model], approx = False , **few_shot_params ) # (params.method == 'maml_approx')\n",
        "    if params.dataset in ['omniglot', 'cross_char']: #maml use different parameter in omniglot\n",
        "        model.n_task     = 32\n",
        "        model.task_update_num = 1\n",
        "        model.train_lr = 0.1\n",
        "else:\n",
        "   raise ValueError('Unknown method')\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "checkpoint_dir = '%s/checkpoints/%s/%s_%s' %(save_dir, params.dataset, params.model, params.method)\n",
        "if params.train_aug:\n",
        "    checkpoint_dir += '_aug'\n",
        "if not params.method in ['baseline', 'baseline++'] :\n",
        "    checkpoint_dir += '_%dway_%dshot' %( params.train_n_way, params.n_shot)\n",
        "\n",
        "#modelfile   = get_resume_file(checkpoint_dir)\n",
        "\n",
        "if not params.method in ['baseline', 'baseline++'] : \n",
        "    if params.save_iter != -1:\n",
        "        modelfile   = get_assigned_file(checkpoint_dir,params.save_iter)\n",
        "    else:\n",
        "        modelfile   = get_best_file(checkpoint_dir)\n",
        "    if modelfile is not None:\n",
        "        tmp = torch.load(modelfile)\n",
        "        model.load_state_dict(tmp['state'])\n",
        "\n",
        "split = params.split\n",
        "if params.save_iter != -1:\n",
        "    split_str = split + \"_\" +str(params.save_iter)\n",
        "else:\n",
        "    split_str = split\n",
        "if params.method in ['maml', 'maml_approx']: #maml do not support testing with feature\n",
        "    if 'Conv' in params.model:\n",
        "        if params.dataset in ['omniglot', 'cross_char']:\n",
        "            image_size = 28\n",
        "        else:\n",
        "            image_size = 84 \n",
        "    else:\n",
        "        image_size = 224\n",
        "\n",
        "    datamgr         = SetDataManager(image_size, n_eposide = iter_num, n_query = 15 , **few_shot_params)\n",
        "\n",
        "    if params.dataset == 'cross':\n",
        "        if split == 'base':\n",
        "            loadfile = data_dir['miniImagenet'] + 'all.json' \n",
        "        else:\n",
        "            loadfile   = data_dir['CUB'] + split +'.json'\n",
        "    elif params.dataset == 'cross_char':\n",
        "        if split == 'base':\n",
        "            loadfile = data_dir['omniglot'] + 'noLatin.json' \n",
        "        else:\n",
        "            loadfile  = data_dir['emnist'] + split +'.json' \n",
        "    else: \n",
        "        loadfile    = data_dir[params.dataset] + split + '.json'\n",
        "\n",
        "    novel_loader     = datamgr.get_data_loader( loadfile, aug = False)\n",
        "    if params.adaptation:\n",
        "        model.task_update_num = 100 #We perform adaptation on MAML simply by updating more times.\n",
        "    model.eval()\n",
        "    acc_mean, acc_std = model.test_loop( novel_loader, return_std = True)\n",
        "\n",
        "else:\n",
        "    novel_file = os.path.join( checkpoint_dir.replace(\"checkpoints\",\"features\"), split_str +\".hdf5\") #defaut split = novel, but you can also test base or val classes\n",
        "    cl_data_file = feat_loader.init_loader(novel_file)\n",
        "\n",
        "    for i in range(iter_num):\n",
        "        acc = feature_evaluation(cl_data_file, model, n_query = 15, adaptation = params.adaptation, **few_shot_params)\n",
        "        acc_all.append(acc)\n",
        "\n",
        "    acc_all  = np.asarray(acc_all)\n",
        "    acc_mean = np.mean(acc_all)\n",
        "    acc_std  = np.std(acc_all)\n",
        "    print('%d Test Acc = %4.2f%% +- %4.2f%%' %(iter_num, acc_mean, 1.96* acc_std/np.sqrt(iter_num)))\n",
        "with open('./record/results.txt' , 'a') as f:\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime()) \n",
        "    aug_str = '-aug' if params.train_aug else ''\n",
        "    aug_str += '-adapted' if params.adaptation else ''\n",
        "    if params.method in ['baseline', 'baseline++'] :\n",
        "        exp_setting = '%s-%s-%s-%s%s %sshot %sway_test' %(params.dataset, split_str, params.model, params.method, aug_str, params.n_shot, params.test_n_way )\n",
        "    else:\n",
        "        exp_setting = '%s-%s-%s-%s%s %sshot %sway_train %sway_test' %(params.dataset, split_str, params.model, params.method, aug_str , params.n_shot , params.train_n_way, params.test_n_way )\n",
        "    acc_str = '%d Test Acc = %4.2f%% +- %4.2f%%' %(iter_num, acc_mean, 1.96* acc_std/np.sqrt(iter_num))\n",
        "    f.write( 'Time: %s, Setting: %s, Acc: %s \\n' %(timestamp,exp_setting,acc_str)  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyc6qB0IXgjn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "\n",
        "cwd = os.getcwd() \n",
        "data_path = './drive/My Drive/CUB/images/'\n",
        "savedir = './drive/My Drive/CUB/'\n",
        "dataset_list = ['base','val','novel']\n",
        "\n",
        "#if not os.path.exists(savedir):\n",
        "#    os.makedirs(savedir)\n",
        "\n",
        "folder_list = [f for f in listdir(data_path) if isdir(join(data_path, f))]\n",
        "folder_list.sort()\n",
        "label_dict = dict(zip(folder_list,range(0,len(folder_list))))\n",
        "\n",
        "classfile_list_all = []\n",
        "\n",
        "for i, folder in enumerate(folder_list):\n",
        "    folder_path = join(data_path, folder)\n",
        "    classfile_list_all.append( [ join(folder_path, cf) for cf in listdir(folder_path) if (isfile(join(folder_path,cf)) and cf[0] != '.')])\n",
        "    random.shuffle(classfile_list_all[i])\n",
        "\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    file_list = []\n",
        "    label_list = []\n",
        "    for i, classfile_list in enumerate(classfile_list_all):\n",
        "        if 'base' in dataset:\n",
        "            if (i%2 == 0):\n",
        "                file_list = file_list + classfile_list\n",
        "                label_list = label_list + np.repeat(i, len(classfile_list)).tolist()\n",
        "        if 'val' in dataset:\n",
        "            if (i%4 == 1):\n",
        "                file_list = file_list + classfile_list\n",
        "                label_list = label_list + np.repeat(i, len(classfile_list)).tolist()\n",
        "        if 'novel' in dataset:\n",
        "            if (i%4 == 3):\n",
        "                file_list = file_list + classfile_list\n",
        "                label_list = label_list + np.repeat(i, len(classfile_list)).tolist()\n",
        "\n",
        "    fo = open(savedir + dataset + \".json\", \"w\")\n",
        "    fo.write('{\"label_names\": [')\n",
        "    fo.writelines(['\"%s\",' % item  for item in folder_list])\n",
        "    fo.seek(0, os.SEEK_END) \n",
        "    fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "    fo.write('],')\n",
        "\n",
        "    fo.write('\"image_names\": [')\n",
        "    fo.writelines(['\"%s\",' % item  for item in file_list])\n",
        "    fo.seek(0, os.SEEK_END) \n",
        "    fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "    fo.write('],')\n",
        "\n",
        "    fo.write('\"image_labels\": [')\n",
        "    fo.writelines(['%d,' % item  for item in label_list])\n",
        "    fo.seek(0, os.SEEK_END) \n",
        "    fo.seek(fo.tell()-1, os.SEEK_SET)\n",
        "    fo.write(']}')\n",
        "\n",
        "    fo.close()\n",
        "    print(\"%s -OK\" %dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUtO0M78Hqmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_of_lists(N):\n",
        "    total = 0\n",
        "    for i in range(5):\n",
        "        L = [j ^ (j >> i) for j in range(N)]\n",
        "        total += sum(L)\n",
        "    return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohE32l5THq9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%prun sum_of_lists(1000000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBSqBa4uHsaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load Recycle-GAN/data/base_data_loader.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC7xaC5sH-cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%file Recycle-GAN/data/base_data_loader.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDWO6ssIEtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}